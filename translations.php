<?php
	$GLOBALS['translations'] = array(
		'en' => array(
			"predicted_category" => "Predicted category",
			"correct_category" => "Correct category",
			"model_was_set" => "Model was set properly",
			'example_csv_shoe_size' => 'Load example shoe data (0 = male, 1 = female)',
			'we_want_to_train_this_model_5_categories' => 'The computer should now learn to classify the images into one of the five categories.',
			'fire' => 'Fire prevention',
			'mandatory' => 'Mandatory',
			'prohibition' => 'Prohibition',
			'rescue' => 'Rescue',
			'warning' => 'Warning',
			'the_more_variations_the_model_sees' => 'The more variations the model sees, the better it can learn important features of the images.',
			'quality_depends_on_random' => 'The quality of the results depends on randomness.',
			'program_looks_at_data' => 'The learning process (training) is now running and the computer tries, through trial and error, many different filter configurations.',
			'the_further_on_top_the_better' => "Especially at the beginning of the training, many images are initially classified into the wrong category. As the training progresses, the correct category is increasingly assigned, and this assignment becomes more reliable. The categorical assignment is more reliable the higher an image moves up into the blue area.",
			'add_category' => 'Add category',
			'settings' => 'Settings',
			'description' => 'Description',
			'use_bias' => 'Use Bias',
			'activation_function' => 'Activation function',
			'bias_initializer' => 'Bias-Initializer',
			'kernel_initializer' => 'Kernel-Initializer',
			'trainable' => 'Trainable',
			'visualize_layer' => 'Visualize layer',
			'visualize_this_layer' => 'Visualize this layer',
			'examples' => 'Examples',
			'dataset' => 'Dataset',
			'height' => 'Height',
			'width' => 'Width',
			'batch_size' => 'Batch-Size',
			'epochs' => 'Epochs',
			'own_data' => 'Data Source',
			'filters' => 'Filters',
			'distribution' => 'Distribution',
			'image_options' => 'Image Options',
			'feature_extraction' => 'Feature ex&shy;traction',
			'classification' => 'Classi&shy;fication',
			'flatten' => 'Flatten',
			'dataset_and_network' => 'Dataset and network',
			'visualization' => 'Model Visualization',
			'data' => 'Data',
			'training_data' => 'Data',
			'currently_the_network_has_seen' => 'The remaining time of this training will be',
			'of' => 'of',
			'times_seen' => 'times.',
			'it_will_take_about' => 'It will take about',
			'remain_left' => ' ',
			'camera_draw_self' => 'Camera/draw',
			'click_on' => 'Touch',
			'if_bad_continue_training' => 'If the results are still bad, continue training.',
			'the_ai_thinks_categories_look_like_this' => 'A visual representation of what the AI has learnt',
			'it_might_only_be_noise' => "That's why you are probably only seeing random noise and the detection may not work properly yet.",
			'image_left' => 'image left',
			'images_left' => 'images left',
			'beginner' => 'Beginner',
			'expert' => 'Expert',
			'except_last_layer' => 'except last layer',
			'activation_functions' => 'Activation functions',
			'set_for_all_layers' => 'Set for all layers',
			'shuffle_before_each_epoch' => 'Shuffle before each epoch',
			'summary' => 'Summary',
			'own_images' => 'Own images',
			'own_tensor' => 'Own tensors',
			'kernel_size' => 'Kernel-Size',
			'start_training' => 'Start training',
			'stop_training' => 'Stop training',
			'imprint' => 'Imprint',
			'change_shape' => 'Change shape',
			'simulate_real_data' => 'Simulate real data',
			'dimensionality_reduction' => 'Di&shy;men&shy;sio&shy;na&shy;lity re&shy;duc&shy;tion',
			'shy_activation_function' => 'Ac&shy;ti&shy;va&shy;tion fun&shy;ction',
			'shy_overfitting_prevention' => 'Pre&shy;vent Over&shy;fit&shy;ting',
			'rescale_and_recenter' => 'Re-scale and re-center data',
			'show_layer_data_flow' => 'Show layer data flow',
			'show_grad_cam' => 'Show gradCAM',
			'code' => 'Code',
			'own_csv' => 'Own CSV',
			'training' => 'Training',
			'predict' => 'Predict',
			'hyperparameters' => 'Hyperparameters',
			'valsplit' => 'Val.-Split',
			'divide_x_by' => 'Divide <i>X</i> by',
			'metric' => 'Metric',
			'loss' => 'Loss',
			'optimizer' => 'Optimizer',
			'learning_rate' => 'Learning Rate',
			'enable_tf_debug' => 'Enable TFJS Debugger',
			'enable_webcam' => 'Enable webcam',
			'disable_webcam' => 'Disable webcam',
			'switch_to_other_cam' => 'Switch to other cam',
			'copy_to_clipboard' => 'Copy to clipboard',
			'copy_to_clipboard_debug' => 'Copy to clipboard (debug)',
			'set_all_initializers' => 'Set all Initializers',
			'augmentation' => 'Augmentation',
			'iterations' => 'Iterations',
			'close' => 'Close',
			'register' => 'Register',
			'csv' => 'CSV',
			'math' => 'Math',
			'smaller' => 'Smaller',
			'larger' => 'Larger',
			'reset' => 'Reset',
			'delete_predictions' => 'Delete predictions',
			'memory_usage_while_training' => 'Memory usage while training (per batch)',
			'img_per_cat' => 'Img/cat',
			'batches' => 'Batches',
			'login' => 'Login',
			'username' => 'Username',
			'password' => 'Password',
			'download' => 'Download',
			'email' => 'E-Mail',
			'public' => 'Public',
			'save' => 'Save',
			'augment' => 'Augment',
			'download_model_data' => 'Download model data',
			'logout' => 'Logout',
			'load' => 'Load',
			'download_for_local_taurus' => 'Download for local/taurus training',
			'max_activated_neurons' => 'Max. activated neurons',
			'no_default_data' => 'Default data',
			'yes_own_tensor' => '&#x2318; Own tensor-data',
			'yes_own_csv' => '&#128290; Own CSV',
			'yes_own_images' => '&#128444; Own images/webcam',
			'width_amp_height' => 'Width&amp;height (0 = auto)',
			'randomizer_limits' => 'Randomizer Limits',
			'max_neurons_fcnn' => 'Max. neurons FCNN',
			'various_plots' => 'Various Plots',
			'sources_and_used_programs' => 'Sources and used programs',
			'visualize_images_in_grid' => 'Visualize images in grid',
			'model_compiled_successfully' => 'Model compiled successfully',
			'not_creating_model_because_values_are_missing' => 'Not creating model because some values are missing',
			'tensors' => 'Tensors',
			'set_val_split_to' => 'Set validationSplit to ',
			'set_optimizer_to' => 'Setting optimizer to ',
			'set_metric_to' => 'Setting metric to ',
			'set_loss_to' => 'Setting loss to ',
			'show_bars_instead_of_numbers' => 'Show bars instead of numbers',
			'number_of_grid_images' => 'Number of grid images',
			'show_raw_data' => 'Show raw data',
			'pixel_size' => 'Pixel size',
			'auto_rotate_images' => 'Auto rotate images',
			'number_of_rotations' => 'Number of rotations',
			'pretext_prepare_data' => 'You must prepare your dataset yourself! You can use this piece of code to generate the data file in the correct format after you pre-processed them.',
			'reinitialize_weights' => 'Reinitialize weights',
			'batch_plot_minimum_time' => 'Batch-Plot-Minimum-Time',
			'loss_metric_data_and_shape' => 'Loss, Metric, Data and Shapes',
			'sine_ripple' => 'Sine-Ripple',
			'invert_images' => 'Invert images',
			'flip_left_right' => 'Flip left and right',
			'layer_data_flow' => 'Layer data flow',
			'dense_description' => 'Creates a dense (fully connected) layer.<br>This layer implements the operation: <span class="temml_me">\\mathrm{output} = \\mathrm{activation}\\left(\\mathrm{input} \\cdot \\mathrm{kernel} + \\text{bias}\\right)</span>. Activation is the element-wise activation function passed as the activation argument.<br><tt>kernel</tt> is a weights matrix created by the layer.<br><tt>bias</tt> is a bias vector created by the layer (only applicable if useBias is true).',
			'flatten_description' => 'Flattens the input. Does not affect the batch size. A Flatten layer flattens each batch in its inputs to 1D (making the output 2D).',
			'dropout_description' => 'Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.',
			'reshape_description' => 'Reshapes an input to a certain shape.',
			"elu_description" => "Exponential Linear Unit (ELU).<br>Equation: <span class='temml_me'>\\text{elu}\\left(x\\right) = \\left\\{\\begin{array}{ll} \\alpha \\cdot \\left(e^x - 1\\right) & \\text{for } x < 0 \\\\ \n x & \\text{for } x >= 0\\end{array}\\right.</span>",
			"leakyReLU_description" => "Leaky version of a rectified linear unit.<br>It allows a small gradient when the unit is not active: <span class='temml_me'>\\text{leakyReLU}(x) = \\left\\{\\begin{array}{ll} \\alpha \\cdot x & \\text{for } x < 0 \\\\ \n x & \\text{for } x >= 0 \\end{array}\\right.</span>",
			'reLU_description' => 'Rectified Linear Unit activation function. <span class="temml_me">\\mathrm{relu}\\left(x\\right) = \\mathrm{max}\\left(\mathrm{Max-Value}, x\\right)</span>',
			'softmax_description' => 'Softmax activation layer. <span class="temml_me">\\mathrm{softmax}\\left(x\\right) = \\frac{e^{z_j}}{\\sum^K_{k=1} e^{z_k}}</span>',
			"thresholdedReLU_description" => "Thresholded Rectified Linear Unit. Equation: <span class='temml_me'>f(x) = \\left\\{\\begin{array}{ll} x & \\text{for } x > \\theta \\\\ \n 0 & \\text{otherwise}\\end{array}\\right.</span>",
			'batchNormalization_description' => "Batch normalization layer (<a href='https://arxiv.org/abs/1502.03167' target='_blank'>Ioffe and Szegedy, 2014</a>).<br>Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.",
			'layerNormalization_description' => "Layer-normalization layer (<a target='_blank' href='https://arxiv.org/abs/1607.06450'>Ba et al., 2016</a>). Normalizes the activations of the previous layer for each given example in a batch independently, instead of across a batch like in batchNormalization. In other words, this layer applies a transformation that maintanis the mean activation within each example close to 0 and activation variance close to 1.",
			'conv1d_description' => '1D convolution layer (e.g., temporal convolution).<br>This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs.<br>If <tt>use_bias</tt> is True, a bias vector is created and added to the outputs.<br>If <tt>activation</tt> is not <tt>null</tt>, it is applied to the outputs as well.',
			'conv2d_description' => '2D convolution layer (e.g. spatial convolution over images).<br>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.<br>If <tt>useBias</tt> is True, a bias vector is created and added to the outputs.<br>If <tt>activation</tt> is not null, it is applied to the outputs as well.',
			'conv2dTranspose_description' => 'Transposed convolutional layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.',
			'conv3d_description' => '3D convolution layer (e.g. spatial convolution over volumes).<br>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.',
			'depthwiseConv2d_description' => 'Depthwise separable 2D convolution. Depthwise Separable convolutions consists in performing just the first step in a depthwise spatial convolution (which acts on each input channel separately). The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'separableConv2d_description' => 'Depthwise separable 2D convolution. Separable convolution consists of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'upSampling2d_description' => 'Upsampling layer for 2D inputs. Repeats the rows and columns of the data by <tt>size[0]</tt> and <tt>size[1]</tt> respectively.',
			'averagePooling1d_description' => 'Average pooling operation for spatial data.',
			'averagePooling2d_description' => 'Average pooling operation for spatial data.',
			'averagePooling3d_description' => 'Average pooling operation for 3d data.',
			'maxPooling1d_description' => 'Max pooling operation for temporal data.',
			'maxPooling2d_description' => 'Global max pooling operation for spatial data.',
			'maxPooling3d_description' => 'Global max pooling operation for 3d data.',
			'alphaDropout_description' => 'Applies Alpha Dropout to the input. As it is a regularization layer, it is only active at training time.',
			'gaussianDropout_description' => 'Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'gaussianNoise_description' => 'Apply additive zero-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'DebugLayer_description' => "Log internal state of the data to the developer's console (like <tt>console.log</tt>). Does nothing to the data itself and returns them unchanged.",
			'max_number_of_values' => 'Max number of values (0 = no limit)',
			'provide_x_data' => 'Provide X-data file',
			'provide_y_data' => 'Provide Y-data file',
			'download_custom_zip_file' => 'Download custom data in a .zip file',
			'delay_between_images' => 'Delay in seconds between images in a series',
			'number_of_images_in_series' => 'Number of images in a series',
			'restart_fcnn' => "Restart FCNN",
			'undo_redo_stack_lost' => 'Undo/redo stack lost!',
			'changing_mode_deletes_stack' => 'Changing the mode deletes the undo/redo stack.',
			'auto_adjust_last_layer_if_dense' => "Auto-adjust last layer's number of neurons (if Dense)",
			'load_images' => 'Load Images',
			"loading_data" => 'Loading data',
			'ai_tries_to_draw' => 'The AI tries to draw how it thinks the categories look like...',
			'stop_generating_images' => 'Stop generating images',
			'stopped_generating_images' => "Stopped generating new images, this may take a while",
			'now_being' => 'Now, ',
			'images_of_each_category' => 'Images of each categories are being loaded.',
			'one_second' => "1 second",
			'years' => 'years',
			'year' => 'year',
			'minutes' => 'minutes',
			'minute' => 'minute',
			'seconds' => 'seconds',
			"hours" => "hours",
			'second' => 'second',
			'days' => 'days',
			'day' => 'day',
			'left' => 'left',
			"example_images" => "Example Images",
			"and_try_to_draw_a_warning_sign" => "and try to draw a warning sign",
			"go_back_to_examples" => "to go back to example images",
			'the_training_was_only_with' => 'The training has been done with only',
			'images_and' => 'images and',
			'epochs_done' => 'epochs done. Thus, the results are probably bad',
			'this_may_take_a_while' => 'This may take a while',
			"loading_images_into_memory" => "Loading images into memory",
			"train_the_neural_network" => "Tap here to train neural network",
			"train_further" => "Train the network further",
			"loading_model" => "Loading model",
			"loading_example_images" => "Loading example images",
			"undoing_redoing" => "Undoing/redoing",
			"skip_presentation" => "Skip &rarr;",
			"very_unsure" => "Very unsure",
			"quite_unsure" => "Quite unsure",
			"a_bit_unsure" => "A bit unsure",
			"neutral" => "A bit sure",
			"relatively_sure" => "Relatively sure",
			"very_sure" => "Very sure",
			"time_per_batch" => "Time per Batch",
			"training" => "Training",
			"done_training_took" => "Done Training, took",
			"done_generating_images" => "Done generating images",
			"generating_image_for_neuron" => "Generating image for neuron",
			"failed_try_again" => "failed. Trying again",
			"fixing_output_shape" => "Output shape is being fixed...",
			"output_shape_repaired" => "Output shape repaired",
			"please_try_training_again" => 'Please try training again',
			'No' => 'No',
			'Yes' => 'Yes',
			'autofix_output_shape' => 'Do you want to automatically fix the output shape?',
			'defective_output_shape' => 'Defective output shape detected',
			"switched_to_beginner_mode" => "Switched to beginner mode",
			"beginner" => "Beginner",
			"expert" => "Expert",
			'changed_mode_from' => "Changed mode from",
			"to" => "to",
			"lost_undo_redo_stack" => "lost undo/redo stack",
			"stopped_training" => "Stopped training",
			"updating_predictions" => "Updating predictions",
			"loaded_configuration" => "Loaded configuration",
			"model_is_not_defined" => "Model is not defined",
			"model_is_ok" => "Model is OK",
			"got_data" => "Got data, tensors created",
			"site_is_ready" => "Site is ready",
			"trying_to_set_backend" => "Trying to set backend",
			"backend_set" => "Backend set",
			"set_theme" => "Set theme",
			"theme_set" => "Theme set",
			"has_cookie_for" => "Has cookie for",
			"initializing_losses" => "Initializing losses",
			"initializing_metrics" => "Initializing metrics",
			"setting_backend" => "Setting backend",
			"properly_set_backend" => "Backend set properly",
			"width" => "width",
			"height" => "height",
			"changing" => "Changing",
			"changed_data_source" => "Changed data source",
			"hiding_augmentation" => "Hiding augmentation",
			"showing_augmentation" => "Showing augmentation",
			"input_shape_is_read_only" => "The Input-Shape read-only",
			"input_shape_is_writable" => "The Input-Shape is editable",
			"updating_page" => "Updating page...",
			"page_update_took" => "Page update took",
			"getting_labels" => "Getting labels",
			"compiling_model" => "Compiling model",
			"done_changing" => "Done changing",
			"took" => "took",
			"setting_layer" => "Setting layer",
			"setting_options_for_layer" => "Setting options for layer",
			"creating_model" => "Creating model",
			"graph_explanation" => "The lines in the graph represent the error. The lower the line, the smaller the error.<hr class='cosmo_hr'>The blue line indicates the improvements on the data that the network is trained on, while the orange line indicates how well it performs on data it hasn't seen before.<hr class='cosmo_hr'>Both lines should decrease and look somewhat similar for the training to be progressing well.",
			"previous_images" => "Previous images",
			"current_images" => "Current images",
			"predictions_explanation_while_training" => "Down below is one example of each category. The bars show the calculated likelihood of the image to be in that category. The most strongly detected category is green. You can see the Categories change as the network learns.",
			"prohibition" => "Prohibition",
			'Brandschutz' => 'Fire prevention',
			'Verbot' => 'Prohibition',
			'Gebot' => 'Mandatory',
			'Rettung' => 'Rescue',
			'Warnung' => 'Warning',
			"currently" => "Currently",
			"correct" => "correct",
			"wrong" => "Wrong",
			"total" => "Total",
			"images_are_being_detected_correctly" => "images are being detected correctly",
			"category" => "Kategorie",
			"percentage_correct" => "Percentage correct",
			"training_done_text" => "The training phase is complete. If the accuracy is still insufficient, the network can be further trained to potentially achieve better results.",
			"initializing_categories" => "Initializing categories",
			"initializing_tabs" => "Initialisiere Tabs",
			"initializing_page_contents" => "Initializing page contents",
			"initializing_set_options_for_all" => "Initializing 'set options for all'",
			"got_data_creating_tensors" => "Got data, creating tensors...",
			"started_training" => "Started training",
			"compiling model" => "Compiling model",
			"compiled_model" => "Compiled model",
			"finished_training" => "Finished training",
			"stopped_downloading_because_button_was_clicked" => "Stop downloading because stop-download-button was clicked",
			"weight_matrix" => "Weight matrix",
			"weight_matrices" => "Weight matrices",
			"kernel_pixel_size" => "Kernel-pixel-size",
			"shuffle_data_before_validation_split" => "Shuffle data before doing validation split (recommended)?",
			"separator" => "Seperator",
			"auto_adjust_last_layer_neurons" => "Auto-adjust last layer's number of neurons?",
			"auto_one_hot_encoding" => 'Auto One-Hot-encode Y (disables "divide by")?',
			"auto_loss_metric" => "Auto loss/metric?",
			"auto_set_last_layer_to_linear" => "Auto-set last layer's activation to linear when any Y-values are smaller than 0 or greater than 1?",
			"divide_by" => "Divide by",
			"load_custom_function_csv" => "Load custom function (from, to, stepsize)",
			"loading_the_site_took" => "Loading the site took",
			"site_was_active" => "Page was active",
			"site_was_inactive" => "Page was inactive",
			"input_image" => "Input data",
			"generated_image" => "Generated data",
			"weights" => "Weights",
			"bias" => "Bias",
			"activation_function_of_neuron" => "Activation function of Neuron/Filter",
			"maximally_activated_explanation" => "The neuron visualization method utilizes an input image (x) to generate a resulting image (x∗). It involves utilizing the weights (W) and bias (b) of a neuron to apply an activation function (f(x;W,b)) to the input image. This activation function determines how strongly the neuron responds to specific features in the image. The result is determined using the argmax function, which identifies the region in the image that triggers the highest activation of the neuron. This region is then further refined to optimize the generated image. The process is iterative, adjusting the input image based on the gradients of the activation function until the desired outcome is achieved.",
			"start" => "Start",
			"end" => "End",
			"stepsize" => "Stepsize",
			"function_with_explanation" => "Function (use x and/or y as variables and JavaScript-Functions like <tt>Math.sin(x)</tt>)",
			"no_header_lines_found" => "No header line found",
			"no_data_lines_found" => "No data lines found",
			"duplicate_header_entries_found" => "Duplicate header entries found",
			"remove_data_img_predictions" => "Remove predictions",
			"beta1" => "&beta;<sub>1</sub>",
			"beta2" => "&beta;<sub>2</sub>",
			"epsilon" => "&epsilon;",
			"rho" => "&rho;",
			"initial_accumulator_value" => "Initial Accumulator Value",
			"decay" => "Decay",
			"momentum" => "Momentum",
			"no_decimal_points_math_mode" => "Number of decimal points (0 = no limit)",
			"max_nr_vals" => "Maximum number of rows/columns per matrix",
			"train_visualization_only_works_for_default_data" => "Train visualization only works for default data.",
			"train_visualization_only_works_for_classification_problems" => "Train visualization only works for default data.",
			"train_visualization_only_works_for_images" => "Train visualization only works for images.",
			"train_visualization_only_works_when_last_layer_is_softmax" => "Train visualization only works when the last layer has the SoftMax-activation function.",
			"setting_width" => "Setting width",
			"setting_height" => "Setting height",
			"model_not_given" => "Model not given",
			"could_not_get_model" => "Could not get model",
			"privacy_tainted_no_longer_screenshots" => "Privacy is tainted. Bug reports will no longer contain screenshots.",
			"stop_downloading_start_training" => "Stop downloading and start training",
			"failed_to_add_layer_type" => "Failed to add layer type:",
			"the_loaded_model_has_no_layers" => "The loaded model has no layers",
			"old_model_had_no_layers" => "Old model had no layers defined",
			"no_layers_found" => "No layers found",
			"no_model_found" => "No model found"
		),

		'de' => array(
			"predicted_category" => "Vorhergesagte Kategorie",
			"correct_category" => "Richtige Kategorie",
			"model_was_set" => "Modell erfolgreich gesetzt",
			'example_csv_shoe_size' => 'Schuhbeispiel-CSV laden (0 = männlich, 1 = weiblich)',
			'Brandschutz' => 'Brandschutz',
			'Gebot' => 'Gebot',
			'we_want_to_train_this_model_5_categories' => 'Der Computer soll nun lernen, Bilder in die jeweils passende der fünf vorgegebenen Kategorien einzuordnen.',
			'fire' => 'Brandschutz',
			'mandatory' => 'Gebot',
			'prohibition' => 'Verbot',
			'rescue' => 'Rettung',
			'warning' => 'Warnung',
			'the_more_variations_the_model_sees' => 'Je mehr Variationen das Modell sieht, desto besser kann es die wichtigsten Merkmale der Bilder lernen.',
			'quality_depends_on_random' => 'Die Qualität des Ergebnisses hängt vom Zufall ab.',
			'program_looks_at_data' => 'Der Lernprozess (das Training) läuft jetzt und der Computer probiert durch Versuch und Irrtum sehr viele verschiedene Filterkonfigurationen aus.',
			'the_further_on_top_the_better' => "Insbesondere am Anfang des Trainings werden viele Bilder noch in die falsche Kategorie eingeordnet. Im weiteren Verlauf wird dann zunehmend jeweils die richtige Kategorie zugeordnet, wobei diese Zuordnung auch immer zuverlässiger ist. Diese kategoriale Zuordnung ist umso zuverlässiger, je weiter ein Bild nach oben in den blauen Bereich wandert.",
			'add_category' => 'Kategorie hinzufügen',
			'settings' => 'Einstellungen',
			'description' => 'Be&shy;schrei&shy;bung',
			'use_bias' => 'Bias benutzen',
			'activation_function' => 'Aktivier&shy;ungs&shy;fun&shy;ktion',
			'bias_initializer' => 'Bias-Initialisierer',
			'kernel_initializer' => 'Kernel-Initialisierer',
			'trainable' => 'Trainierbar',
			'visualize_layer' => 'Layer visualisieren',
			'visualize_this_layer' => 'Diesen Layer visualisieren',
			'examples' => 'Beispiele',
			'dataset' => 'Datensatz',
			'height' => 'Höhe',
			'width' => 'Breite',
			'batch_size' => 'Batchgröße',
			'epochs' => 'Epochen',
			'own_data' => 'Datenquelle',
			'filters' => 'Filter',
			'distribution' => 'Verteilung',
			'image_options' => 'Bildoptionen',
			'feature_extraction' => 'Merkmalsex&shy;traktion',
			'classification' => 'Klassi&shy;fikation',
			'flatten' => 'Verflachen',
			'dataset_and_network' => 'Datensatz und Netzwerk',
			'visualization' => 'Modellvisualisierung',
			'data' => 'Daten',
			'training_data' => 'Daten',
			'currently_the_network_has_seen' => 'Die verbleibende Zeit in dieser Trainingsphase beträgt noch ca.',
			'of' => 'von',
			'times_seen' => 'mal angesehen',
			'it_will_take_about' => 'Es wird noch ca.',
			'remain_left' => 'dauern',
			'camera_draw_self' => 'Kamera/selbstmalen',
			'click_on' => 'Berühre',
			'if_bad_continue_training' => 'Wenn die Ergebnisse noch zu schlecht sind, trainiere weiter.',
			'the_ai_thinks_categories_look_like_this' => 'Eine visuelle Repräsentation dessen, was die KI gelernt hat',
			'it_might_only_be_noise' => 'Daher sehen Sie hier wahrscheinlich nur Rauschen und die Erkennung geht noch nicht.',
			'image_left' => 'Bild übrig',
			'images_left' => 'Bilder übrig',
			'beginner' => 'Anfänger',
			'expert' => 'Experte',
			'except_last_layer' => 'außer letztem Layer',
			'activation_functions' => 'Aktivierungsfunktionen',
			'set_for_all_layers' => 'Einstellungen für alle Layer',
			'shuffle_before_each_epoch' => 'Vor jeder Epoche zufällig sortieren',
			'summary' => 'Zusammenfassung',
			'own_images' => 'Eigene Bilder',
			'own_tensor' => 'Eigene Tensoren',
			'kernel_size' => 'Kernel-Größe',
			'start_training' => 'Training starten',
			'stop_training' => 'Training stoppen',
			'imprint' => 'Impressum',
			'change_shape' => 'Shape verändern',
			'simulate_real_data' => 'Echten Daten simulieren',
			'dimensionality_reduction' => 'Di&shy;men&shy;sio&shy;ns&shy;re&shy;duk&shy;tion',
			'shy_activation_function' => 'Ak&shy;ti&shy;vier&shy;ungsfun&shy;ktion',
			'shy_overfitting_prevention' => 'Over&shy;fit&shy;ting ver&shy;hinderung',
			'rescale_and_recenter' => 'Reskalierung und Zentrierung',
			'show_layer_data_flow' => 'Datenfluss anzeigen',
			'show_grad_cam' => 'gradCAM anzeigen',
			'code' => 'Quellcode',
			'own_csv' => 'Eigene CSV',
			'training' => 'Training',
			'predict' => 'Predict',
			'hyperparameters' => 'Hyperparameter',
			'valsplit' => 'Val.-Split',
			'divide_x_by' => 'Teile <i>X</i> durch',
			'metric' => 'Metrik',
			'loss' => 'Loss',
			'optimizer' => 'Optimierer',
			'learning_rate' => 'Lernrate',
			'enable_tf_debug' => 'TFJS Debugger aktivieren',
			'enable_webcam' => 'Webcam aktivieren',
			'disable_webcam' => 'Webcam deaktivieren',
			'switch_to_other_cam' => 'Zur anderen Kamera wechseln',
			'copy_to_clipboard' => 'In Zwischenablage kopieren',
			'copy_to_clipboard_debug' => 'In Zwischenablage kopieren (Debug)',
			'set_all_initializers' => 'Setze alle Initialisierer',
			'augmentation' => 'Augmentierung',
			'iterations' => 'Iterationen',
			'close' => 'Schließen',
			'register' => 'Registrieren',
			'csv' => 'CSV',
			'math' => 'Mathe',
			'smaller' => 'Kleiner',
			'larger' => 'Größer',
			'reset' => 'Reset',
			'delete_predictions' => 'Predictions löschen',
			'memory_usage_while_training' => 'Speicherverbrauch während des Trainings (pro Batch)',
			'img_per_cat' => 'Bilder/Kat.',
			'batches' => 'Batches',
			'login' => 'Anmelden',
			'username' => 'Benutzername',
			'password' => 'Passwort',
			'download' => 'Herunterladen',
			'email' => 'E-Mail',
			'public' => 'Öffentlich',
			'save' => 'Speichern',
			'augment' => 'Augmentieren',
			'download_model_data' => 'Modelldaten downloaden',
			'logout' => 'Abmelden',
			'load' => 'laden',
			'download_for_local_taurus' => 'Für lokales oder Taurus-Training herunterladen',
			'max_activated_neurons' => 'Maximal aktivierte Neuronen',
			'no_default_data' => 'Standarddaten',
			'yes_own_tensor' => '&#x2318; eigene Tensordaten',
			'yes_own_csv' => '&#128290; eigene CSV',
			'yes_own_images' => '&#128444; eigene Bilder/Webcam',
			'width_amp_height' => 'Höhe&amp;Breite (0 = auto)',
			'randomizer_limits' => 'Randomisierergrenzen',
			'max_neurons_fcnn' => 'Max. Neuronen FCNN',
			'various_plots' => 'Verschiedene Plots',
			'sources_and_used_programs' => 'Quellen',
			'visualize_images_in_grid' => 'Bilder in Grid visualisieren',
			'model_compiled_successfully' => 'Modell erfolgreich kompiliert',
			'not_creating_model_because_values_are_missing' => 'Kann Modell nicht erstellen, weil Werte fehlen',
			'tensors' => 'Tensoren',
			'set_val_split_to' => 'Setze den Validation-Split auf ',
			'set_optimizer_to' => 'Setze den Optimierer auf ',
			'set_metric_to' => 'Setze die Metrik auf ',
			'set_loss_to' => 'Setze den Loss auf ',
			'show_bars_instead_of_numbers' => 'Balken statt Zahlen verwenden',
			'number_of_grid_images' => 'Anzahl Bilder im Grid',
			'show_raw_data' => 'Rohdaten anzeigen',
			'pixel_size' => 'Pixelgröße',
			'auto_rotate_images' => 'Bilder automatisch rotieren',
			'number_of_rotations' => 'Anzahl Rotationen',
			'pretext_prepare_data' => 'Sie müssen Ihre Daten selbst vorbereiten! Sie können folgenden Code nehmen, um Datenstrukturen aus Python in das richtige Format umzuwandeln, das Sie mit asanAI benutzen können.',
			'reinitialize_weights' => 'Gewichte reinitialisieren',
			'batch_plot_minimum_time' => 'Minimale Zeit zwischen Batch-Plots',
			'loss_metric_data_and_shape' => 'Loss, Metrik, Daten und Shapes',
			'sine_ripple' => 'Sinus-Kräusel',
			'invert_images' => 'Bilder invertieren',
			'flip_left_right' => 'Bilder spiegeln',
			'layer_data_flow' => 'Layer-Datenfluss',
			'dense_description' => 'Erstellt eine dichte (vollständig verbundene) Schicht.<br>Diese Schicht implementiert die Operation: <span class="temml_me">\\mathrm{output} = \\mathrm{activation}\\left(\\mathrm{input} \\cdot \\mathrm{kernel} + \\text{bias}\\right)</span>. Die Aktivierung ist die elementweise Aktivierungsfunktion, die als Aktivierungsargument übergeben wird.<br><tt>kernel</tt> ist eine Gewichtsmatrix, die von der Schicht erstellt wird.<br><tt>bias</tt> ist ein Bias-Vektor, der von der Schicht erstellt wird (nur anwendbar, wenn useBias true ist).',
			'flatten_description' => 'Flacht die Eingabe ab. Beeinflusst nicht die Batch-Größe. Eine Flatten-Schicht macht in ihren Eingaben jede Batch in 1D flach (wodurch die Ausgabe 2D wird).',
			'dropout_description' => 'Dropout besteht darin, eine Bruchteilrate der Eingabeeinheiten während jeder Aktualisierung während der Trainingszeit zufällig auf 0 zu setzen, was Überanpassung verhindert.',
			'reshape_description' => 'Formt eine Eingabe in eine bestimmte Form um.',
			"elu_description" => "Exponential Linear Unit (ELU).<br>Gleichung: <span class='temml_me'>\\text{elu}\\left(x\\right) = \\left\\{\\begin{array}{ll} \\alpha \\cdot \\left(e^x - 1\\right) & \\text{for } x < 0 \\\\ \n x & \\text{for } x >= 0\\end{array}\\right.</span>",
			"leakyReLU_description" => "Leaky-Version einer rektifizierten linearen Einheit.<br>Sie erlaubt eine kleine Steigung, wenn die Einheit nicht aktiv ist: <span class='temml_me'>\\text{leakyReLU}(x) = \\left\\{\\begin{array}{ll} \\alpha \\cdot x & \\text{for } x < 0 \\\\ \n x & \\text{for } x >= 0 \\end{array}\\right.</span>",
			'reLU_description' => 'Aktivierungsfunktion der rektifizierten linearen Einheit. <span class="temml_me">\\mathrm{relu}\\left(x\\right) = \\mathrm{max}\\left(\mathrm{Max-Value}, x\\right)</span>',
			'softmax_description' => 'Softmax-Aktivierungsschicht. <span class="temml_me">\\mathrm{softmax}\\left(x\\right) = \\frac{e^{z_j}}{\\sum^K_{k=1} e^{z_k}}</span>',
			"thresholdedReLU_description" => "Thresholded Rectified Linear Unit. Gleichung: <span class='temml_me'>f(x) = \\left\\{\\begin{array}{ll} x & \\text{for } x > \\theta \\\\ \n 0 & \\text{otherwise}\\end{array}\\right.</span>",
			'batchNormalization_description' => "Batch-Normalisierungsschicht (<a href='https://arxiv.org/abs/1502.03167' target='_blank'>Ioffe and Szegedy, 2014</a>).<br>Normalisieren Sie die Aktivierungen der vorherigen Schicht in jeder Batch, d.h. wendet eine Transformation an, die die mittlere Aktivierung nahe bei 0 und die Aktivierungsstandardabweichung nahe bei 1 hält.",
			'layerNormalization_description' => "Normalisierungsschicht (<a target='_blank' href='https://arxiv.org/abs/1607.06450'>Ba et al., 2016</a>). Normalisieren Sie die Aktivierungen der vorherigen Schicht für jedes gegebene Beispiel in einer Batch unabhängig voneinander, anstatt in einer Batch wie in der Batch-Normalisierung. Mit anderen Worten, diese Schicht wendet eine Transformation an, die die mittlere Aktivierung innerhalb jedes Beispiels nahe bei 0 und die Aktivierungsvarianz nahe bei 1 hält.",
			'conv1d_description' => '1D-Faltungs-Schicht (z.B. zeitliche Faltung).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht über eine einzelne räumliche (oder zeitliche) Dimension gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.<br>Wenn <tt>use_bias</tt> True ist, wird ein Bias-Vektor erstellt und den Ausgaben hinzugefügt.<br>Wenn <tt>activation</tt> nicht <tt>null</tt> ist, wird es auch auf die Ausgaben angewendet.',
			'conv2d_description' => '2D-Faltungs-Schicht (z.B. räumliche Faltung über Bilder).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.<br>Wenn <tt>useBias</tt> True ist, wird ein Bias-Vektor erstellt und den Ausgaben hinzugefügt.<br>Wenn <tt>activation</tt> nicht null ist, wird es auch auf die Ausgaben angewendet.',
			'conv2dTranspose_description' => 'Transponierte Faltungsschicht (manchmal auch Deconvolution genannt). Der Bedarf an transponierten Faltungen ergibt sich in der Regel aus dem Wunsch, eine Transformation in die entgegengesetzte Richtung einer normalen Faltung zu verwenden, d.h. von etwas, das die Form der Ausgabe einiger Faltungen hat, zu etwas, das die Form ihres Eingangs hat, während ein Konnektivitätsmuster beibehalten wird, das mit dieser Faltung kompatibel ist.',
			'conv3d_description' => '3D-Faltungs-Schicht (z.B. räumliche Faltung über Volumen).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.',
			'depthwiseConv2d_description' => 'Tiefe separierbare 2D-Faltung. Tiefe separierbare Faltungen bestehen darin, nur den ersten Schritt einer tiefen räumlichen Faltung durchzuführen (die auf jede Eingabeschicht separat wirkt). Das Argument "depthMultiplier" steuert, wie viele Ausgabeschichten pro Eingabeschicht im Tiefe-Schritt generiert werden.',
			'separableConv2d_description' => 'Tiefe separierbare 2D-Faltung. Separierbare Faltung besteht darin, zuerst eine räumliche Faltung in der Tiefe (die auf jede Eingabeschicht separat wirkt) durchzuführen, gefolgt von einer punktweisen Faltung, die die resultierenden Ausgabeschichten miteinander vermischt. Das Argument "depthMultiplier" steuert, wie viele Ausgabeschichten pro Eingabeschicht im Tiefe-Stufen-Schritt generiert werden.',
			'upSampling2d_description' => 'Upsampling-Schicht für 2D-Eingaben. Wiederholt die Zeilen und Spalten der Daten jeweils um <tt>size[0]</tt> bzw. <tt>size[1]</tt> Mal.',
			'averagePooling1d_description' => 'Durchschnittliche Pooling-Operation für räumliche Daten.',
			'averagePooling2d_description' => 'Durchschnittliche Pooling-Operation für räumliche Daten.',
			'averagePooling3d_description' => 'Durchschnittliche Pooling-Operation für 3d Daten.',
			'maxPooling1d_description' => 'Maximale Pooling-Operation für zeitliche Daten.',
			'maxPooling2d_description' => 'Globale Max-Pooling-Operation für räumliche Daten.',
			'maxPooling3d_description' => 'Globale Max-Pooling-Operation für 3d Daten.',
			'alphaDropout_description' => 'Wendet Alpha-Dropout auf die Eingabe an. Da es sich um eine Regularisierungsschicht handelt, ist sie nur während des Trainings aktiv.',
			'gaussianDropout_description' => 'Wendet multiplikatives gaußsches Rauschen mit einer Zentrierung um 1 an. Da es sich um eine Regularisierungsschicht handelt, ist sie nur während des Trainings aktiv.',
			'gaussianNoise_description' => 'Füge additive gaußsches Rauschen mit einer Null-Zentrierung hinzu. Da es sich um eine Regularisierungsschicht handelt, ist sie nur während des Trainings aktiv.',
			'DebugLayer_description' => 'Protokolliert den internen Zustand der Daten in die Entwicklerkonsole (wie <tt>console.log</tt>). Tut nichts mit den Daten selbst und gibt sie unverändert zurück.',
			'max_number_of_values' => 'Maximale Anzahl an Werten (0 = kein Limit)',
			'provide_x_data' => 'X-Daten',
			'provide_y_data' => 'Y-Daten',
			'download_custom_zip_file' => 'Downloade die eigenen Daten als .zip-Datei',
			'delay_between_images' => 'Wartezeit zwischen den Bildern in der Serie',
			'number_of_images_in_series' => 'Anzahl Bilder pro Serie',
			'restart_fcnn' => "FCNN neustarten",
			'undo_redo_stack_lost' => 'Rückgängig/wiederherstellen-Stack verloren!',
			'changing_mode_deletes_stack' => 'Das ändern des Modus löscht den gesamten Undo/Redo-Stack.',
			'auto_adjust_last_layer_if_dense' => "Automatisch den letzten Layer anpassen (wenn Dense)",
			'load_images' => 'Lade Bilder',
			"loading_data" => 'Lade Daten',
			'ai_tries_to_draw' => 'Die KI versucht zu malen, wie sie diese Kategorien gelernt hat...',
			'stop_generating_images' => 'Bildgenerierung stoppen',
			'stopped_generating_images' => "Die Bildgenerierung wurde gestoppt. Das kann einen Moment dauern.",
			'now_being' => 'Jetzt werden',
			'images_of_each_category' => 'Bilder aus jeder Kategorie geladen.',
			'one_second' => "1 Sekunde",
			'years' => 'Jahre',
			'year' => 'Jahr',
			'minutes' => 'Minuten',
			'minute' => 'Minute',
			'seconds' => 'Sekunden',
			"hours" => "Stunden",
			'second' => 'Sekunde',
			'days' => 'Tage',
			'day' => 'Tag',
			'left' => 'übrig',
			"example_images" => "Beispielbilder",
			"and_try_to_draw_a_warning_sign" => "und versuche ein Warnschild zu malen",
			"go_back_to_examples" => "um zu den Beispielbildern zurückzugehen",
			'the_training_was_only_with' => 'Das Training wurde mit insgesamt nur',
			'images_and' => 'Bildern und',
			'epochs_done' => 'Epochen gemacht. Die Ergebnisse sind also wahrscheinlich schlecht',
			'this_may_take_a_while' => 'Das kann einen Moment dauern',
			"loading_images_into_memory" => "Lade die Bilder in den Speicher",
			"train_the_neural_network" => "Hier klicken, um neuronales Netz zu trainieren",
			"train_further" => "Das Netzwerk weiter trainieren",
			"loading_model" => "Lade Modell",
			"loading_example_images" => "Lade Beispielbilder",
			"undoing_redoing" => "Rückgängig machen/wiederherstellen",
			"skip_presentation" => "Überspringen &rarr;",
			"very_unsure" => "Sehr unsicher",
			"quite_unsure" => "Eher unsicher",
			"a_bit_unsure" => "Ein wenig unsicher",
			"neutral" => "Ein wenig sicher",
			"relatively_sure" => "Relativ sicher",
			"very_sure" => "Sehr sicher",
			"time_per_batch" => "Zeit pro Batch",
			"training" => "Training",
			"done_training_took" => "Training fertig, es dauerte",
			"done_generating_images" => "Bilder fertig generiert",
			"generating_image_for_neuron" => "Generiere Bild für Neuron",
			"failed_try_again" => "fehlgeschlagen. Versuche es erneut",
			"fixing_output_shape" => "Output-Shape wird repariert",
			"output_shape_repaired" => "Output shape repariert",
			"please_try_training_again" => 'Bitte erneut trainieren',
			'No' => 'Nein',
			'Yes' => 'Ja',
			'autofix_output_shape' => 'Möchten Sie die Output-Shape automatisch reparieren lassen?',
			'defective_output_shape' => 'Kaputte Output-Shape entdeckt!',
			"switched_to_beginner_mode" => "In den Anfängermodus gewechselt",
			"beginner" => "Anfänger",
			"expert" => "Experte",
			'changed_mode_from' => "Modus von",
			"to" => "nach",
			"lost_undo_redo_stack" => "Rückgängig/wiederherstellen resettet",
			"stopped_training" => "Training beendet",
			"updating_predictions" => "Aktualisiere Predictions",
			"loaded_configuration" => "Konfiguration geladen",
			"model_is_not_defined" => "Modell ist nicht definiert",
			"model_is_ok" => "Modell ist OK",
			"got_data" => "Daten geholt, Tensoren erstellt",
			"site_is_ready" => "Seite fertig geladen",
			"trying_to_set_backend" => "Versuche, das Backend zu setzen",
			"backend_set" => "Backend gesetzt",
			"set_theme" => "Setze Theme",
			"theme_set" => "Theme gesetzt",
			"has_cookie_for" => "Hat Cookie für",
			"initializing_losses" => "Initialisiere Losses",
			"initializing_metrics" => "Initialisiere Metriken",
			"setting_backend" => "Setze Backend",
			"properly_set_backend" => "Backend erfolgreich gesetzt",
			"width" => "Breite",
			"height" => "Höhe",
			"changing" => "Ändere",
			"changed_data_source" => "Datenquelle geändert",
			"hiding_augmentation" => "Augmentierung versteckt",
			"showing_augmentation" => "Augmentierung gezeigt",
			"input_shape_is_read_only" => "Die Input-Shape ist nur lesbar",
			"input_shape_is_writable" => "Die Input-Shape ist bearbeitbar",
			"updating_page" => "Update die Seite...",
			"page_update_took" => "Das Seitenupdate brauchte",
			"getting_labels" => "Hole Labels",
			"compiling_model" => "Kompiliere Modell",
			"done_changing" => "Fertig mit Ändern der",
			"took" => "brauchte",
			"setting_layer" => "Setze Layer",
			"setting_options_for_layer" => "Setze Optionen für Layer",
			"creating_model" => "Erstelle Modell",
			"graph_explanation" => "Die Linien im Graphen zeigen den Fehler an. Umso niedriger die Linie, desto geringer der Fehler.<hr class='cosmo_hr'>Die blaue Linie zeigt die Verbesserungen auf den Daten, auf denen das Netzwerk trainiert.<hr class='cosmo_hr'>Die orange Linie zeigt an, wie gut es es auf Daten ist, die es nicht gesehen hat.<br>Beide Linien sollten niedriger werden und etwa ähnlich aussehen, damit das Training gut läuft.",
			"previous_images" => "Vorherige Bilder",
			"current_images" => "Aktuelle Bilder",
			"predictions_explanation_while_training" => "Unten ist je ein Beispiel aus jeder Kategorie. Die Balken zeigen, wie viel Prozent die jeweilige Kategorie erkannt wurde. Die am meisten erkannte Kategorie ist grün. Sie können live sehen, wie sich die Kategorien verändern, während das Netzwerk lernt.",
			"prohibition" => "Verbot",
			"Verbot" => "Verbot",
			"Rettung" => "Rettung",
			"Warnung" => "Warnung",
			"currently" => "Aktuell",
			"correct" => "richtig",
			"wrong" => "Falsch",
			"total" => "Gesamt",
			"images_are_being_detected_correctly" => "Bilder wurden richtig erkannt",
			"category" => "Kategorie",
			"percentage_correct" => "Prozent richtig",
			"training_done_text" => "Diese Trainingsphase ist abgeschlossen. Sollte die Genauigkeit noch nicht ausreichend sein, kann das Netz weiter trainiert werden, um möglicherweise bessere Ergebnisse zu erzielen.",
			"initializing_categories" => "Kategorien werden initialisiert",
			"initializing_tabs" => "Initialisiere Tabs",
			"initializing_page_contents" => "Initialisiere Seiteninhalte",
			"initializing_set_options_for_all" => "Initialisiere 'Setze Optionen für alle Layer'",
			"got_data_creating_tensors" => "Daten geholt, erstelle Tensoren...",
			"started_training" => "Training gestartet",
			"compiling model" => "Kompiliere Modell",
			"compiled_model" => "Modell kompiliert",
			"finished_training" => "Training beendet",
			"stopped_downloading_because_button_was_clicked" => "Download gestoppt, weil der Download-Stoppen-Button geklickt wurde",
			"weight_matrix" => "Gewichtungsmatrix",
			"weight_matrices" => "Gewichtungsmatrizen",
			"kernel_pixel_size" => "Kernel-Pixelgröße",
			"shuffle_data_before_validation_split" => "Daten zufällig sortieren, bevor der Validierungsdatensatz abgespalten wird (empfohlen)?",
			"separator" => "Trennzeichen",
			"auto_adjust_last_layer_neurons" => "Die Anzahl der Neuronen im letzten Layer automatisch anpassen?",
			"auto_one_hot_encoding" => 'Automatisches One-Hot-Encoding (Deaktiviert "teilen durch")?',
			"auto_loss_metric" => "Automatischer Loss/Metrik?",
			"auto_set_last_layer_to_linear" => "Automatisch die Aktivierungsfunktion des letzten Layers auf Linear setzen, wenn die Outputs kleiner 0 oder größer 1 sind?",
			"divide_by" => "Teilen durch",
			"load_custom_function_csv" => "Benutzerdefinierte Funktion (von, bis, Schrittgröße)",
			"loading_the_site_took" => "Das Laden der Seite brauchte",
			"site_was_active" => "Seite war aktiv",
			"site_was_inactive" => "Seite war inaktiv",
			"input_image" => "Eingabedaten",
			"generated_image" => "Generierte Daten",
			"weights" => "Gewichte",
			"bias" => "Bias",
			"activation_function_of_neuron" => "Aktivierungsfunktion eines Neurons/Filters",
			"maximally_activated_explanation" => "Die Visualisierungsmethode für Neuronen verwendet ein Eingangsbild (x), um ein generiertes Bild (x∗) zu erstellen. Dabei werden die Gewichte (W) und der Bias (b) eines Neurons verwendet, um eine Aktivierungsfunktion (f(x;W,b)) auf das Eingangsbild anzuwenden. Diese Aktivierungsfunktion bestimmt, wie stark das Neuron auf bestimmte Merkmale im Bild reagiert. Das Ergebnis wird durch die argmax-Funktion bestimmt, die den Bereich im Bild identifiziert, der die höchste Aktivierung des Neurons auslöst. Dieser Bereich wird dann weiter verfeinert, um das generierte Bild zu optimieren. Der Prozess wird iterativ durchgeführt, indem das Eingangsbild basierend auf den Gradienten der Aktivierungsfunktion angepasst wird, bis das gewünschte Ergebnis erreicht ist.",
			"start" => "Start",
			"end" => "Ende",
			"stepsize" => "Schrittgröße",
			"function_with_explanation" => "Funktion (x und/oder y als Variablenname und JavaScript-Funktionen wie <tt>Math.sin(x)</tt>)",
			"no_header_lines_found" => "Keine Überschriftenzeile gefunden",
			"no_data_lines_found" => "Keine Datenzeilen gefunden",
			"duplicate_header_entries_found" => "Doppelte Überschriften gefunden",
			"remove_data_img_predictions" => "Vorhersagen entfernen",
			"beta1" => "&beta;<sub>1</sub>",
			"beta2" => "&beta;<sub>2</sub>",
			"epsilon" => "&epsilon;",
			"rho" => "&rho;",
			"initial_accumulator_value" => "Initial Accumulator Value",
			"decay" => "Decay",
			"momentum" => "Momentum",
			"no_decimal_points_math_mode" => "Anzahl Nachkommanstellen (0 = kein Limit)",
			"max_nr_vals" => "Maximale Anzahl an Spalten/Zeilen pro Matrix",
			"train_visualization_only_works_for_default_data" => "Die Trainingsvisualisierung funktioniert nur für Standarddaten.",
			"train_visualization_only_works_for_classification_problems" => "Die Trainingsvisualisierung funktioniert nur für Klassifikationsprobleme.",
			"train_visualization_only_works_for_images" => "Die Trainingsvisualisierung funktioniert nur für Bilddaten.",
			"train_visualization_only_works_when_last_layer_is_softmax" => "Die Trainingsvisualisierung funktioniert nur, wenn der letzte Layer die Aktivierungsfunktion SoftMax hat.",
			"setting_width" => "Setze Breite",
			"setting_height" => "Setze Höhe",
			"model_not_given" => "Modell nicht gesetzt",
			"could_not_get_model" => "Konnte Modell nicht holen",
			"privacy_tainted_no_longer_screenshots" => "Die Privatsphäre ist beeinträchtigt. Fehlerberichte werden keine Screenshots mehr enthalten.",
			"stop_downloading_start_training" => "Stoppe den Download und beginne das Training",
			"failed_to_add_layer_type" => "Der Layer-Typ konnte nicht hinzugefügt werden:",
			"the_loaded_model_has_no_layers" => "Das geladene Modell hat keine Layer",
			"old_model_had_no_layers" => "Das alte Modell hatte keine Layer",
			"no_layers_found" => "Keine Layer gefunden",
			"no_model_found" => "Kein Modell gefunden"
		)
	);

	function checkSubElementsKeys($array) {
		$keys = [];

		foreach ($array as $subArray) {
			if (!is_array($subArray)) {
				die("Sub-element is not an array");
			}

			$subKeys = array_keys($subArray);

			if (empty($keys)) {
				$keys = $subKeys;
			} elseif ($keys !== $subKeys) {
				$missingKeys = array_diff($keys, $subKeys);
				if($missingKeys) {
					die("Missing key: " . reset($missingKeys));
				}
			}
		}

		return true;
	}

	if(!checkSubElementsKeys($GLOBALS["translations"])) {
		die("Sub-elements do not have the same keys");
	}

	if(isset($_GET["print"])) {
		print json_encode($translations);
	}
?>
