// loss_landscape_live.js (stable + dynamic grid + masking + stable 3D camera - FIXED)
// Requires: tf (TFJS), Plotly (global). Designed to run in browser.

// --- Utilities: flatten / metadata for weights ---
function sanitize_z_matrix(xs, ys, z) {
Â  Â  if (!Array.isArray(xs) || !Array.isArray(ys) || !Array.isArray(z)) return { ok: false, reason: 'bad_inputs' };
Â  Â  const [nx, ny] = [xs.length, ys.length];
Â  Â  if (ny === 0) return { ok: false, reason: 'empty_z' };

Â  Â  let sum = 0, finite_count = 0;
Â  Â  const finite_values = [];

Â  Â  for (let i = 0; i < ny; i++) {
Â  Â  Â  Â  const row = z[i];
Â  Â  Â  Â  if (!Array.isArray(row) || row.length !== nx) return { ok: false, reason: 'z_mismatch' };
Â  Â  Â  Â  for (let j = 0; j < nx; j++) {
Â  Â  Â  Â  Â  Â  const v = row[j];
Â  Â  Â  Â  Â  Â  if (typeof v === 'number' && isFinite(v)) {
Â  Â  Â  Â  Â  Â  Â  Â  finite_count++;
Â  Â  Â  Â  Â  Â  Â  Â  sum += v;
Â  Â  Â  Â  Â  Â  Â  Â  finite_values.push(v);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  }

Â  Â  const total = nx * ny;
Â  Â  const fraction_finite = finite_count / total;
Â  Â  if (finite_count === 0 || fraction_finite < 0.05) return { ok: false, reason: 'too_many_missing', fraction: fraction_finite };

Â  Â  const mean = (finite_count > 0) ? (sum / finite_count) : 0;
Â  Â  let z_output = z;
Â  Â  let filled = false;

Â  Â  if (fraction_finite < 1.0) {
Â  Â  Â  Â  filled = true;
Â  Â  Â  Â  z_output = z.map(row =>
Â  Â  Â  Â  Â  Â  row.map(v => (typeof v === 'number' && isFinite(v)) ? v : mean)
Â  Â  Â  Â  );
Â  Â  }

Â  Â  return { ok: true, z: z_output, nx, ny, fraction: fraction_finite, filled, mean };
}

function product(arr){
Â  var p=1;
Â  for(var i=0;i<arr.length;i++) p*=arr[i];
Â  return p;
}

function get_shape_from_array(arr, shape=[]){
Â  if (!Array.isArray(arr)) return shape;
Â  shape.push(arr.length);
Â  if (arr.length > 0) return get_shape_from_array(arr[0], shape);
Â  return shape;
}

function flatten(arr, out=[]){
Â  for(var i=0;i<arr.length;i++){
Â  Â  if(Array.isArray(arr[i])){
Â  Â  Â  flatten(arr[i], out);
Â  Â  } else {
Â  Â  Â  out.push(arr[i]);
Â  Â  }
Â  }
Â  return out;
}

function flatten_weights(weights_json){
Â  var meta = {shapes:[],sizes:[],offsets:[]};
Â  var total = 0;
Â  for(var i=0;i<weights_json.length;i++){
Â  Â  var shape = get_shape_from_array(weights_json[i]);
Â  Â  var size = product(shape);
Â  Â  meta.shapes.push(shape);
Â  Â  meta.sizes.push(size);
Â  Â  meta.offsets.push(total);
Â  Â  total += size;
Â  }
Â  var vec = new Float32Array(total);
Â  for(var i=0;i<weights_json.length;i++){
Â  Â  var flat = flatten(weights_json[i], []);
Â  Â  var off = meta.offsets[i];
Â  Â  for(var j=0;j<meta.sizes[i];j++) vec[off+j] = flat[j];
Â  }
Â  meta.total = total;
Â  return {vector:vec,meta:meta};
}

function unflatten_to_tensors(vector, meta){
Â  var arr = [];
Â  for(var i=0;i<meta.shapes.length;i++){
Â  Â  var off = meta.offsets[i];
Â  Â  var size = meta.sizes[i];
Â  Â  var slice = vector.subarray(off, off+size);
Â  Â  var t = tf.tensor(slice, meta.shapes[i]);
Â  Â  arr.push(t);
Â  }
Â  return arr;
}

function vector_to_weights_json(vector, meta){
Â  var out = [];
Â  for(var i=0;i<meta.shapes.length;i++){
Â  Â  var off = meta.offsets[i];
Â  Â  var size = meta.sizes[i];
Â  Â  var flat = Array.prototype.slice.call(vector.subarray(off, off+size));
Â  Â  var shape = meta.shapes[i];
Â  Â  function build(shape, flat_ref){
Â  Â  Â  if(shape.length === 0) return flat_ref.shift();
Â  Â  Â  var n = shape[0];
Â  Â  Â  var subshape = shape.slice(1);
Â  Â  Â  var res = [];
Â  Â  Â  for(var j=0;j<n;j++) res.push(build(subshape, flat_ref));
Â  Â  Â  return res;
Â  Â  }
Â  Â  var copy = flat.slice();
Â  Â  out.push(build(shape, copy));
Â  }
Â  return out;
}

// --- Snapshot store & helpers ---
function make_snapshot_store(max_snapshots = 200) {
Â  Â  const store = {
Â  Â  Â  Â  meta: null,
Â  Â  Â  Â  snapshots: [], // Float32Array per snapshot
Â  Â  Â  Â  losses: [],
Â  Â  Â  Â  times: [],
        // NEU: Speichern der letzten Komponenten fÃ¼r die StabilitÃ¤t
        last_comps: null,
Â  Â  Â  Â  last_mean: null
Â  Â  };

Â  Â  store.add_snapshot = (vec, loss) => {
Â  Â  Â  Â  if (!store.meta) throw new Error("meta not set. Call init_with_meta(meta) first.");
Â  Â  Â  Â  if (store.snapshots.length >= max_snapshots) {
Â  Â  Â  Â  Â  Â  store.snapshots.shift();
Â  Â  Â  Â  Â  Â  store.losses.shift();
Â  Â  Â  Â  Â  Â  store.times.shift();
Â  Â  Â  Â  }
Â  Â  Â  Â  store.snapshots.push(vec.slice());
Â  Â  Â  Â  store.losses.push(typeof loss === 'number' ? loss : NaN);
Â  Â  Â  Â  store.times.push(Date.now());
Â  Â  };

    store.set_projection_basis = (comps, mean) => {
        store.last_comps = comps;
        store.last_mean = mean;
    };


Â  Â  store.init_with_meta = (meta) => { store.meta = meta; };
Â  Â  store.get_matrix = () => store.snapshots;
Â  Â  store.get_n = () => store.snapshots.length;
Â  Â  store.get_d = () => store.meta ? store.meta.total : 0;

Â  Â  store.compute_proj_bbox = (proj_coords, pad_fraction = 0.12) => {
Â  Â  Â  Â  if (!proj_coords || proj_coords.length === 0) return { x: [-1, 1], y: [-1, 1] };

Â  Â  Â  Â  const xs = proj_coords.map(p => p[0]);
Â  Â  Â  Â  const ys = proj_coords.map(p => p[1]);

Â  Â  Â  Â  let min_x = Math.min(...xs), max_x = Math.max(...xs);
Â  Â  Â  Â  let min_y = Math.min(...ys), max_y = Math.max(...ys);

Â  Â  Â  Â  const min_span_limit = 1e-3;

Â  Â  Â  Â  let span_x = Math.max(max_x - min_x, min_span_limit);
Â  Â  Â  Â  let span_y = Math.max(max_y - min_y, min_span_limit);

Â  Â  Â  Â  // Ensure minimal span for non-degenerate grid
Â  Â  Â  Â  if (span_x === min_span_limit) { min_x -= 0.5; max_x += 0.5; span_x = 1.0; }
Â  Â  Â  Â  if (span_y === min_span_limit) { min_y -= 0.5; max_y += 0.5; span_y = 1.0; }

Â  Â  Â  Â  const pad_x = span_x * pad_fraction;
Â  Â  Â  Â  const pad_y = span_y * pad_fraction;

Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  x: [min_x - pad_x, max_x + pad_x],
Â  Â  Â  Â  Â  Â  y: [min_y - pad_y, max_y + pad_y],
Â  Â  Â  Â  Â  Â  span_x, span_y
Â  Â  Â  Â  };
Â  Â  };

Â  Â  return store;
}

function should_skip_snapshot(new_vector, store) {
Â  Â  const last = store.snapshots[store.snapshots.length - 1];
Â  Â  if (!last || last.length !== new_vector.length) return false;

Â  Â  for (let i = 0; i < last.length; i++) {
Â  Â  Â  Â  if (last[i] !== new_vector[i]) return false;
Â  Â  }
Â  Â  return true;
}

// --- Dimension reduction ---
// ... (Die Funktionen `random_projection`, `compute_mean`, `pca_power_iteration` bleiben unverÃ¤ndert) ...

function compute_mean(rows){
Â  var n = rows.length, D = rows[0].length;
Â  var mean = new Float32Array(D);
Â  for(var i=0;i<n;i++){
Â  Â  var r = rows[i];
Â  Â  for(var j=0;j<D;j++) mean[j]+=r[j];
Â  }
Â  for(var j=0;j<D;j++) mean[j]/=n;
Â  return mean;
}

function pca_power_iteration(rows, k, iterations){
Â  var n = rows.length;
Â  var D = rows[0].length;
Â  var mean = compute_mean(rows);
Â  var X = [];
Â  for(var i=0;i<n;i++){
Â  Â  var r = rows[i];
Â  Â  var c = new Float32Array(D);
Â  Â  for(var j=0;j<D;j++) c[j] = r[j] - mean[j];
Â  Â  X.push(c);
Â  }
Â  function multiply_cov(v){
Â  Â  var u = new Float32Array(n);
Â  Â  for(var i=0;i<n;i++){
Â  Â  Â  var dot = 0;
Â  Â  Â  var xi = X[i];
Â  Â  Â  for(var j=0;j<D;j++) dot += xi[j]*v[j];
Â  Â  Â  u[i] = dot;
Â  Â  }
Â  Â  var w = new Float32Array(D);
Â  Â  for(var i=0;i<n;i++){
Â  Â  Â  var factor = u[i];
Â  Â  Â  var xi = X[i];
Â  Â  Â  for(var j=0;j<D;j++) w[j] += xi[j]*factor;
Â  Â  }
Â  Â  return w;
Â  }
Â  var components = [];
Â  for(var comp_idx=0; comp_idx<k; comp_idx++){
Â  Â  var v = new Float32Array(D);
Â  Â  for(var i=0;i<D;i++) v[i] = Math.random() - 0.5;
Â  Â  for(var it=0; it<(iterations||80); it++){
Â  Â  Â  var w = multiply_cov(v);
Â  Â  Â  for(var p=0;p<components.length;p++){
Â  Â  Â  Â  var c = components[p];
Â  Â  Â  Â  var dotcw = 0;
Â  Â  Â  Â  for(var j=0;j<D;j++) dotcw += c[j]*w[j];
Â  Â  Â  Â  for(var j=0;j<D;j++) w[j] -= dotcw*c[j];
Â  Â  Â  }
Â  Â  Â  var norm = 0;
Â  Â  Â  for(var j=0;j<D;j++) norm += w[j]*w[j];
Â  Â  Â  norm = Math.sqrt(norm)||1;
Â  Â  Â  for(var j=0;j<D;j++) v[j]=w[j]/norm;
Â  Â  }
Â  Â  components.push(v);
Â  }
Â  var proj = new Array(n);
Â  for(var i=0;i<n;i++){
Â  Â  var xi = X[i];
Â  Â  var coords = [];
Â  Â  for(var cidx=0;cidx<components.length;cidx++){
Â  Â  Â  var c = components[cidx];
Â  Â  Â  var dot = 0;
Â  Â  Â  for(var j=0;j<D;j++) dot += xi[j]*c[j];
Â  Â  Â  coords.push(dot);
Â  Â  }
Â  Â  proj[i] = coords;
Â  }
Â  return {proj:proj,components:components,mean:mean};
}

// NEU: Stabilisierung der PCA-Komponenten
function stabilize_components(new_comps, last_comps) {
    if (!last_comps || new_comps.length !== last_comps.length) return new_comps;

    const D = new_comps[0].length;
    let stabilized_comps = [];

    for (let k = 0; k < new_comps.length; k++) {
        let new_v = new_comps[k];
        let last_v = last_comps[k];

        let dot = 0;
        for (let j = 0; j < D; j++) {
            dot += new_v[j] * last_v[j];
        }

        // Wenn die Komponenten in die entgegengesetzte Richtung zeigen (Dot-Produkt negativ), umkehren
        if (dot < 0) {
            new_v = new_v.map(val => -val);
        }
        stabilized_comps.push(new_v);
    }
    return stabilized_comps;
}

function project_with_stabilized_comps(X, comps, mean) {
    var n = X.length;
    var D = X[0].length;
    var proj = new Array(n);
    for(var i=0;i<n;i++){
Â  Â  Â  Â  var xi = X[i];
Â  Â  Â  Â  var coords = [];
Â  Â  Â  Â  for(var cidx=0;cidx<comps.length;cidx++){
Â  Â  Â  Â  Â  Â  var c = comps[cidx];
Â  Â  Â  Â  Â  Â  var dot = 0;
Â  Â  Â  Â  Â  Â  for(var j=0;j<D;j++) dot += (xi[j] - mean[j]) * c[j];
Â  Â  Â  Â  Â  Â  coords.push(dot);
Â  Â  Â  Â  }
Â  Â  Â  Â  proj[i] = coords;
Â  Â  }
    return proj;
}


function compute_projection(rows, dims, projection, iterations, store) {
Â  Â  if(rows.length < 2) return null;
Â  Â  if(projection === 'random'){
Â  Â  Â  var result = random_projection(rows, dims);
      store.set_projection_basis(result.components, null);
Â  Â  Â  return {proj: result.proj, comps: result.components, mean: null};
Â  Â  } else {
Â  Â  Â  var p = pca_power_iteration(rows, dims, iterations);

      // Stabilisierung anwenden
      const stabilized_comps = stabilize_components(p.components, store.last_comps);
      const stabilized_proj = project_with_stabilized_comps(rows, stabilized_comps, p.mean);

      store.set_projection_basis(stabilized_comps, p.mean);
Â  Â  Â  return {proj: stabilized_proj, comps: stabilized_comps, mean: p.mean};
Â  Â  }
}


// --- Plotting (Plotly) ---
// ANPASSUNG DER GRÃ–SSE AUF 600X500
const PLOT_WIDTH = 600;
const PLOT_HEIGHT = 500;


function plot_trajectory_2d(container_id, coords, losses, times){
Â  var x = coords.map(function(c){ return c[0]; });
Â  var y = coords.map(function(c){ return c[1]; });
Â  var trace = {
Â  Â  x:x, y:y, mode:'lines+markers',
Â  Â  marker:{size:4, color:losses, colorbar:{title:'loss'}, showscale:true},
Â  Â  line:{width:2},
Â  Â  text: times.map(function(t){ return new Date(t).toLocaleTimeString(); }),
Â  Â  hovertemplate: 'loss: %{marker.color:.4f}<br>time: %{text}<extra></extra>'
Â  };
Â  var layout = {title:'Weight trajectory (2D)', xaxis:{title:'PC1'}, yaxis:{title:'PC2'}, width:PLOT_WIDTH, height:PLOT_HEIGHT};
Â  Plotly.react(container_id, [trace], layout, {responsive:false});
}

function plot_trajectory_3d(container_id, coords, losses, times){
Â  var x = coords.map(function(c){ return c[0]; });
Â  var y = coords.map(function(c){ return c[1]; });
Â  var z = coords.map(function(c){ return c[2]; });
Â  var trace = {
Â  Â  x:x, y:y, z:z, mode:'lines+markers', type:'scatter3d',
Â  Â  marker:{size:3, color:losses, colorbar:{title:'loss'}, showscale:true},
Â  Â  line:{width:2},
Â  Â  text: times.map(function(t){ return new Date(t).toLocaleTimeString(); }),
Â  Â  hovertemplate: 'loss: %{marker.color:.4f}<br>time: %{text}<extra></extra>'
Â  };
Â  var layout = {title:'Weight trajectory (3D)', width:PLOT_WIDTH, height:PLOT_HEIGHT};
Â  Plotly.react(container_id, [trace], layout, {responsive:false});
}

function plot_surface_and_trajectory(container_id, grid_x, grid_y, z_vals, traj_coords, traj_losses, dims, saved_camera){
Â  try {
Â  Â  if(!Array.isArray(traj_coords) || traj_coords.length===0){
Â  Â  Â  console.warn('plot_surface_and_trajectory: no trajectory coords, plotting surface only if possible.');
Â  Â  }

Â  Â  var is3d = (dims === 3);

Â  Â  var sanitize = sanitize_z_matrix(grid_x, grid_y, z_vals);
Â  Â  if(!sanitize.ok){
Â  Â  Â  console.warn('sanitize_z_matrix failed:', sanitize.reason, sanitize);
Â  Â  Â  // Fallback: Nur die Trajektorie plotten
Â  Â  Â  var fallback_traj = traj_coords.map(function(c){
Â  Â  Â  Â  return (is3d && c.length >= 3) ? c : (c.length >= 2 ? [c[0], c[1], 0] : [c[0]||0, c[1]||0, c[2]||0]);
Â  Â  Â  });
Â  Â  Â  if(!is3d){
Â  Â  Â  Â  var ttrace = { x: fallback_traj.map(c=>c[0]), y: fallback_traj.map(c=>c[1]), mode:'lines+markers', type:'scatter', marker:{size:4, color:traj_losses} };
Â  Â  Â  Â  var layout = {title:'Loss surface (heatmap) + trajectory', width:PLOT_WIDTH, height:PLOT_HEIGHT};
Â  Â  Â  Â  Plotly.react(container_id, [ttrace], layout, {responsive:false});
Â  Â  Â  Â  return;
Â  Â  Â  } else {
Â  Â  Â  Â  var t3 = { x: fallback_traj.map(c=>c[0]), y: fallback_traj.map(c=>c[1]), z: traj_losses,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â mode:'lines+markers', type:'scatter3d', marker:{size:3, color:traj_losses}, line:{width:2} };
        var layout3 = {title:'Loss surface + trajectory', width:PLOT_WIDTH, height:PLOT_HEIGHT, scene: saved_camera ? {camera: saved_camera} : {}};
Â  Â  Â  Â  Plotly.react(container_id, [t3], layout3, {responsive:false});
Â  Â  Â  Â  return;
Â  Â  Â  }
Â  Â  }

Â  Â  var z_clean = sanitize.z;
Â  Â  if(!is3d){
Â  Â  Â  var hm = {
Â  Â  Â  Â  x: grid_x, y: grid_y, z: z_clean, type: 'heatmap', colorscale: 'RdBu', reversescale: true, zsmooth: 'best'
Â  Â  Â  };
Â  Â  Â  var traj2 = {
Â  Â  Â  Â  x: traj_coords.map(c=>c[0]), y: traj_coords.map(c=>c[1]), mode: 'lines+markers', type: 'scatter',
Â  Â  Â  Â  marker: { size: 4, color: traj_losses }, line: { width: 2 }
Â  Â  Â  };
Â  Â  Â  var layout = { title: 'Loss surface (heatmap) + trajectory', width:PLOT_WIDTH, height:PLOT_HEIGHT };
Â  Â  Â  Plotly.react(container_id, [hm, traj2], layout, {responsive:false});
Â  Â  Â  return;
Â  Â  }

Â  Â  var surface = {
Â  Â  Â  x: grid_x, y: grid_y, z: z_clean, type: 'surface', colorscale: 'RdBu', reversescale: true, showscale: true
Â  Â  };
Â  Â  var traj3 = {
Â  Â  Â  x: traj_coords.map(c=>c[0]),
Â  Â  Â  y: traj_coords.map(c=>c[1]),
Â  Â  Â  z: traj_losses, // Loss als Z-Koordinate fÃ¼r die OberflÃ¤che
Â  Â  Â  mode: 'lines+markers', type: 'scatter3d', marker: { size: 3, color: traj_losses }, line: { width: 2 }
Â  Â  };
Â  Â  var layout3 = {
Â  Â  Â  Â  title: 'Loss surface + trajectory',
Â  Â  Â  Â  scene: {
Â  Â  Â  Â  Â  Â  aspectmode: 'manual',
Â  Â  Â  Â  Â  Â  aspectratio: { x: 1, y: 1, z: 0.8 },
            ...(saved_camera && { camera: saved_camera }),
Â  Â  Â  Â  },
Â  Â  Â  Â  width:PLOT_WIDTH,
Â  Â  Â  Â  height:PLOT_HEIGHT
Â  Â  };
    try {
Â  Â  Â  Plotly.react(container_id, [surface, traj3], layout3, {responsive:false});
Â  Â  } catch(e) {
Â  Â  Â  console.error('Plotly.react failed while drawing 3D surface, falling back to trajectory-only', e);
      var layout3_fallback = {title:'Loss surface + trajectory', width:PLOT_WIDTH, height:PLOT_HEIGHT, scene: saved_camera ? {camera: saved_camera} : {}};
Â  Â  Â  Plotly.react(container_id, [traj3], layout3_fallback, {responsive:false});
Â  Â  }
Â  } catch(e) {
Â  Â  console.error('plot_surface_and_trajectory fatal error, drawing trajectory-only', e);
Â  Â  try {
Â  Â  Â  var t = {
Â  Â  Â  Â  x: traj_coords.map(c=>c[0]), y: traj_coords.map(c=>c[1]), z: traj_coords.map(c=>(is3d && c.length>=3) ? c[2] : 0),
Â  Â  Â  Â  mode:'lines+markers',
Â  Â  Â  Â  type: is3d ? 'scatter3d' : 'scatter',
Â  Â  Â  Â  marker:{size:3}
Â  Â  Â  };
Â  Â  Â  Plotly.react(container_id, [t], {width:PLOT_WIDTH, height:PLOT_HEIGHT}, {responsive:false});
Â  Â  } catch(e2) {
Â  Â  Â  console.error('Also failed to draw fallback trajectory', e2);
Â  Â  }
Â  }
}

// --- Grid evaluation (dynamic ranges + masking) ---
async function evaluate_grid_on_plane(store, projection_components, mean_vector, grid_params, eval_fn){
Â  Â  var steps = grid_params.steps || 25;
Â  Â  var rx = grid_params.rangeX || [-1,1];
Â  Â  var ry = grid_params.rangeY || [-1,1];
Â  Â  var center_idx = (typeof grid_params.center_index === 'number') ? grid_params.center_index : (store.get_n()-1);
Â  Â  var center_vec = store.snapshots[center_idx];
Â  Â  var D = center_vec.length;
Â  Â  var proj_coords = grid_params.proj_coords || null;
Â  Â  var center_proj = grid_params.center_proj || [0,0];

    const use_masking = (grid_params.mask_threshold !== null) && (proj_coords && proj_coords.length >= 5);
    const max_allowed = use_masking ? grid_params.mask_threshold : Infinity;

Â  Â  // produce grid axes
Â  Â  var xs = new Array(steps);
Â  Â  var ys = new Array(steps);
Â  Â  for(var i=0;i<steps;i++){
Â  Â  Â  Â  xs[i] = rx[0] + (rx[1]-rx[0]) * i / (steps-1);
Â  Â  Â  Â  ys[i] = ry[0] + (ry[1]-ry[0]) * i / (steps-1);
Â  Â  }
Â  Â  var z = new Array(steps);
Â  Â  for(var i=0;i<steps;i++) z[i] = new Array(steps);

Â  Â  // serial evaluation, but skip distant grid points by writing NaN
Â  Â  for(var ix=0; ix<steps; ix++){
Â  Â  Â  Â  for(var iy=0; iy<steps; iy++){
Â  Â  Â  Â  Â  Â  var gx = xs[ix], gy = ys[iy];
Â  Â  Â  Â  Â  Â  var should_eval = true;

            // Masking check
Â  Â  Â  Â  Â  Â  if(use_masking){
Â  Â  Â  Â  Â  Â  Â  Â  var nearest_sq = Infinity;
Â  Â  Â  Â  Â  Â  Â  Â  for(var pi=0; pi<proj_coords.length; pi++){
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var dx = gx - proj_coords[pi][0];
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var dy = gy - proj_coords[pi][1];
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var d2 = dx*dx + dy*dy;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if(d2 < nearest_sq) nearest_sq = d2;
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  var dist = Math.sqrt(nearest_sq);
Â  Â  Â  Â  Â  Â  Â  Â  if(dist > max_allowed){ should_eval = false; }
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if(!should_eval){
Â  Â  Â  Â  Â  Â  Â  Â  z[iy][ix] = NaN;
Â  Â  Â  Â  Â  Â  Â  Â  continue;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // reconstruct vector: use center projection point as reference
Â  Â  Â  Â  Â  Â  var compX = projection_components[0], compY = projection_components[1];
Â  Â  Â  Â  Â  Â  var delta_x = gx - center_proj[0];
Â  Â  Â  Â  Â  Â  var delta_y = gy - center_proj[1];
Â  Â  Â  Â  Â  Â  var v = new Float32Array(D);
Â  Â  Â  Â  Â  Â  for(var j=0;j<D;j++){
Â  Â  Â  Â  Â  Â  Â  Â  v[j] = center_vec[j] + delta_x * compX[j] + delta_y * compY[j];
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  var weights_json = vector_to_weights_json(v, store.meta);
Â  Â  Â  Â  Â  Â  try{
Â  Â  Â  Â  Â  Â  Â  Â  var loss = await eval_fn(weights_json);
Â  Â  Â  Â  Â  Â  }catch(e){
Â  Â  Â  Â  Â  Â  Â  Â  console.error("eval_fn failed at grid point", e);
Â  Â  Â  Â  Â  Â  Â  Â  var loss = NaN;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  z[iy][ix] = loss;
Â  Â  Â  Â  }
Â  Â  }
Â  Â  return {xs:xs, ys:ys, z:z};
}

// --- Main plotter factory ---
function make_loss_landscape_plotter(opts) {
Â  Â  const {
Â  Â  Â  Â  max_snapshots, container_id, projection = 'pca', dims = 2,
Â  Â  Â  Â  pca_iterations = 80, auto_poll_ms = null, get_weights_fn,
Â  Â  Â  Â  current_loss_fn, grid, eval_fn
Â  Â  } = opts || {};

Â  Â  const store = make_snapshot_store(max_snapshots || 200);
Â  Â  let polling_handle = null;
Â  Â  let render_pending = false;
    let saved_camera = null;

    function setup_camera_listener() {
        const container = document.getElementById(container_id);

        if (container) {
            if (container.hasAttribute('data-camera-listener-setup')) return;

            container.addEventListener('plotly_relayout', function(eventdata) {
                if (eventdata && eventdata['scene.camera']) {
                    saved_camera = eventdata['scene.camera'];
                }
            });
            container.setAttribute('data-camera-listener-setup', 'true');
        }
    }

Â  Â  async function init_from_get_weights() {
Â  Â  Â  Â  if (!get_weights_fn) return;
Â  Â  Â  Â  const wjson = await get_weights_fn();
Â  Â  Â  Â  const { vector, meta } = flatten_weights(wjson);
Â  Â  Â  Â  store.init_with_meta(meta);
Â  Â  Â  Â  store.add_snapshot(vector, NaN);
        setup_camera_listener();
Â  Â  }

Â  Â  async function add_current_snapshot(loss) {
Â  Â  Â  Â  if (!get_weights_fn) {
Â  Â  Â  Â  Â  Â  Â throw new Error("No get_weights_fn provided; call init_with_meta and add_snapshot manually.");
Â  Â  Â  Â  }
Â  Â  Â  Â  const wjson = await get_weights_fn();
Â  Â  Â  Â  const { vector, meta } = flatten_weights(wjson);

Â  Â  Â  Â  if (!store.meta) store.init_with_meta(meta);
Â  Â  Â  Â  if (meta.total !== store.meta.total) {
Â  Â  Â  Â  Â  Â  Â console.error("Weight vector length changed! Cannot snapshot.");
Â  Â  Â  Â  Â  Â  Â return;
Â  Â  Â  Â  }

Â  Â  Â  Â  if (should_skip_snapshot(vector, store)) return;

Â  Â  Â  Â  store.add_snapshot(vector, loss);
Â  Â  Â  Â  update_plot();
Â  Â  }

Â  Â  function add_snapshot_manual(weights_json, loss) {
Â  Â  Â  Â  const { vector, meta } = flatten_weights(weights_json);

Â  Â  Â  Â  if (!store.meta) store.init_with_meta(meta);
Â  Â  Â  Â  if (meta.total !== store.meta.total) {
Â  Â  Â  Â  Â  Â  Â console.error("Weight vector length changed! Cannot snapshot.");
Â  Â  Â  Â  Â  Â  Â return;
Â  Â  Â  Â  }

Â  Â  Â  Â  if (should_skip_snapshot(vector, store)) return;

Â  Â  Â  Â  store.add_snapshot(vector, loss);
Â  Â  Â  Â  update_plot();
Â  Â  }

Â  Â  async function update_plot() {
Â  Â  Â  Â  if (render_pending) return;
Â  Â  Â  Â  render_pending = true;

Â  Â  Â  Â  requestAnimationFrame(async () => {
Â  Â  Â  Â  Â  Â  render_pending = false;
Â  Â  Â  Â  Â  Â  if (!store.meta || store.get_n() < 2) {
Â  Â  Â  Â  Â  Â  Â  Â  if (store.get_n() === 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // FÃ¼r einen einzelnen Punkt verwenden wir random, da PCA 2 Punkte braucht
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const [coord] = store.get_matrix().map(v => random_projection([v, v], dims).proj[0]);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const single_point = (dims === 2) ? plot_trajectory_2d : plot_trajectory_3d;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  single_point(container_id, [coord], [store.losses[0]], [store.times[0]]);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const projection_result = await compute_projection(store.get_matrix(), dims, projection, pca_iterations, store);
Â  Â  Â  Â  Â  Â  if (!projection_result) return;

Â  Â  Â  Â  Â  Â  const { proj: coords, comps, mean } = projection_result;
Â  Â  Â  Â  Â  Â  const { losses, times } = store;

Â  Â  Â  Â  Â  Â  // 1. Plot trajectory (Fallback)
Â  Â  Â  Â  Â  Â  const plot_fn = (dims === 2) ? plot_trajectory_2d : plot_trajectory_3d;
Â  Â  Â  Â  Â  Â  plot_fn(container_id, coords, losses, times);

Â  Â  Â  Â  Â  Â  // 2. Handle grid (surface plotting)
Â  Â  Â  Â  Â  Â  if (grid && grid.enabled && typeof eval_fn === 'function' && comps.length >= 2) {
Â  Â  Â  Â  Â  Â  Â  Â  (async () => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const bbox = store.compute_proj_bbox(coords, grid.pad_fraction || 0.12);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const center_idx = (typeof grid.center_index === 'number') ? grid.center_index : (store.get_n() - 1);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const center_proj = coords[Math.max(0, Math.min(store.get_n() - 1, center_idx))];

                        let mask_threshold = grid.mask_threshold || null;
                        if(store.get_n() < 5) mask_threshold = null;

                        if(mask_threshold === null && coords.length >= 2) {
                            const typical_span = Math.max(bbox.span_x, bbox.span_y, 1e-6);
                            mask_threshold = typical_span * 1.8;
                        }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let grid_params = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  steps: grid.steps || 15,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rangeX: (grid.rangeX && grid.rangeX.length === 2) ? grid.rangeX : bbox.x,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rangeY: (grid.rangeY && grid.rangeY.length === 2) ? grid.rangeY : bbox.y,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  center_index: center_idx,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  proj_coords: coords,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  center_proj: center_proj,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mask_threshold: mask_threshold
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let grid_res = await evaluate_grid_on_plane(store, [comps[0], comps[1]], mean, grid_params, eval_fn);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const coords_for_plot = coords.map(c => (dims === 3) ? (c.length >= 3 ? c : [c[0], c[1], 0]) : (c.length >= 2 ? c : [c[0], 0]));
                        plot_surface_and_trajectory(container_id, grid_res.xs, grid_res.ys, grid_res.z, coords_for_plot, losses, dims, saved_camera);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error("Grid evaluation or plotting failed:", e);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  })();
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });
Â  Â  }

Â  Â  function start_auto_poll() {
Â  Â  Â  Â  if (!get_weights_fn) throw new Error("get_weights_fn required for auto poll.");
Â  Â  Â  Â  if (polling_handle) return;
        setup_camera_listener();

Â  Â  Â  Â  polling_handle = setInterval(async () => {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  const wjson = await get_weights_fn();
Â  Â  Â  Â  Â  Â  Â  Â  const loss = (typeof current_loss_fn === 'function') ? await current_loss_fn() : NaN;
Â  Â  Â  Â  Â  Â  Â  Â  const { vector, meta } = flatten_weights(wjson);

Â  Â  Â  Â  Â  Â  Â  Â  if (!store.meta) store.init_with_meta(meta);

Â  Â  Â  Â  Â  Â  Â  Â  if (should_skip_snapshot(vector, store)) return;

Â  Â  Â  Â  Â  Â  Â  Â  store.add_snapshot(vector, loss);
Â  Â  Â  Â  Â  Â  Â  Â  update_plot();
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error("Auto poll error:", e);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }, auto_poll_ms);
Â  Â  }

Â  Â  function stop_auto_poll() {
Â  Â  Â  Â  if (polling_handle) { clearInterval(polling_handle); polling_handle = null; }
Â  Â  }

Â  Â  return {
Â  Â  Â  Â  store,
Â  Â  Â  Â  init_from_get_weights,
Â  Â  Â  Â  add_current_snapshot,
Â  Â  Â  Â  add_snapshot_manual,
Â  Â  Â  Â  update_plot,
Â  Â  Â  Â  start_auto_poll,
Â  Â  Â  Â  stop_auto_poll,
Â  Â  Â  Â  set_projection: (p) => { projection = p; update_plot(); },
Â  Â  Â  Â  set_dims: (d) => { dims = d; update_plot(); }
Â  Â  };
}

// Hilfsfunktion zum Warten auf die Daten und das Modell
function waitForData(check_fn, timeout_ms = 10000, interval_ms = 200) {
    return new Promise((resolve, reject) => {
        const startTime = Date.now();
        const check = () => {
            if (check_fn()) {
                resolve();
            } else if (Date.now() - startTime > timeout_ms) {
                reject(new Error("Timeout: Erforderliche globale Daten/Modell sind nicht verfÃ¼gbar."));
            } else {
                setTimeout(check, interval_ms);
            }
        };
        check();
    });
}

/**
 * Erstellt eine Kopie des Modells, setzt die Gewichte, kompiliert und evaluiert.
 */
async function copy_model_and_evaluate(weights_json) {
    if (!model_config_json || !X_eval || !Y_eval) {
        console.error("Modellkonfiguration oder Kompilierungskonfiguration fehlen.");
        return NaN;
    }

    // --- ASYNCHRONER TEIL 1: MODELL KLONEN ---
    const cloned_model = await tf.models.modelFromJSON(model_config_json);
    const expected_weight_count = cloned_model.weights.length;

    let loss_value = [NaN];
    let tensors_to_dispose = null;
    let success = false;

    // --- SYNCHRONER TEIL (GPU/CPU-Operationen) in tf.tidy ---
    tf.tidy(() => {
        try {
            // ... (Restlicher Code fÃ¼r flatten_weights, unflatten_to_tensors, setWeights und evaluate) ...

            // 1. Gewichte entflachen und Tensoren erstellen
            const {vector, meta} = flatten_weights(weights_json);
            const tensors = unflatten_to_tensors(vector, meta);
            tensors_to_dispose = tensors;

            // 2. KRITISCHER CHECK (fÃ¼r den Ã¤lteren Fehler)
            if (!Array.isArray(tensors) || tensors.length !== expected_weight_count) {
                console.error(`!!! KRITISCHER FEHLER: UNFLATTEN FEHLGESCHLAGEN. Erwartet: ${expected_weight_count} Tensoren. Erhalten: ${tensors.length} Tensoren.`);
                return;
            }

            // 3. Gewichte setzen und evaluieren
            cloned_model.setWeights(tensors);

            cloned_model.compile(global_model_data);

            const loss_tensor = cloned_model.evaluate(X_eval, Y_eval, {verbose: 0}); // <-- FEHLER WIRD HIER BEHOBEN
            loss_value = loss_tensor.dataSync();
            success = true;

        } catch (e) {
            console.error("Fehler im synchronen tf.tidy-Block (SetWeights/Evaluate):", e);
        }
    });

    // --- MANUELLES DISPOSING ---
    if (cloned_model) cloned_model.dispose();
    if (tensors_to_dispose) tensors_to_dispose.forEach(t => t.dispose());

    return success ? loss_value[0] : NaN;
}

// =================================================================
// ğŸŒ GLOBALE VARIABLEN
// =================================================================

// Globale Variable fÃ¼r die Modell-Architektur-Konfiguration
let model_config_json = null;

// NEU: Globale Variable fÃ¼r die Kopie der Kompilierungskonfiguration (zur Isolierung)
let plotter_compiled_config = null;

// NEU: Speichere die Daten als reine JavaScript-Arrays, um Disposing-Fehler zu vermeiden.
let X_data_array = null;
let Y_data_array = null;

// GLOBALE VARIABLE ZUR FEHLERDROSSELUNG
let landscapeEvaluationErrorCount = 0;
let backendLogged = false;

// =================================================================
// ğŸ›¡ï¸ SICHERER GEWICHTSABRUF (mit erhÃ¶htem Retry)
// =================================================================

/**
 * Versucht, die LÃ¤nge der Gewichte abzurufen, und wiederholt den Versuch bei DisposedError.
 */
async function get_safe_weights_length(max_retries = 15, delay_ms = 200) {
    for (let i = 0; i < max_retries; i++) {
        try {
            // FÃ¼hre den riskanten Aufruf in einem tf.tidy Block aus
            const length = tf.tidy(() => {
                const initial_weights = window.model.getWeights();
                // Hier kÃ¶nnte der Disposed-Fehler auftreten
                const len = initial_weights.length;
                return len; // Tensoren werden von tf.tidy disposed
            });
            // Erfolg: RÃ¼ckgabe der LÃ¤nge
            return length;
        } catch (e) {
            if (e.message && e.message.includes('already disposed')) {
                // Bei "disposed" Fehler: Kurz warten und wiederholen
                console.warn(`WARN: Model weights disposed during read attempt ${i + 1}. Retrying...`);
                await new Promise(resolve => setTimeout(resolve, delay_ms));
            } else {
                // Bei einem anderen Fehler (z.B. TypeError): Den Fehler werfen
                console.error("Unerwarteter Fehler beim Abrufen der Gewichte:", e);
                return 0; // Fehlerfall: 0 Gewichte
            }
        }
    }
    // Nach maximalen Wiederholungen
    console.error(`KRITISCHER FEHLER: Konnte Gewichte nach ${max_retries} Versuchen nicht stabil abrufen.`);
    return 0;
}

// =================================================================
// ğŸ“‹ MODELL KOPIEREN & EVALUIEREN (mit Kompilierungssicherung)
// =================================================================

/**
 * Erstellt eine Kopie des Modells, setzt die Gewichte und evaluiert den Verlust.
 */
async function copy_model_and_evaluate(arg1, arg2) {
    // Checkt jetzt auf die gesicherte Kompilierungskonfiguration
    if (!model_config_json || !X_data_array || !Y_data_array || !plotter_compiled_config) {
        console.error("Modellkonfiguration, Daten oder Kompilierungskonfiguration fehlen.");
        return NaN;
    }

    let current_vector;
    let current_meta;

    // Logik zur Unterscheidung zwischen den beiden Aufruf-Szenarien
    if (arg1 instanceof Float32Array && arg2) {
        current_vector = arg1;
        current_meta = arg2;
    } else if (Array.isArray(arg1) && arg2 === undefined) {
        try {
            const result = flatten_weights(arg1);
            current_vector = result.vector;
            current_meta = result.meta;
        } catch (e) {
            console.error("Fehler beim Abflachen der initialen Gewichts-JSON-Struktur:", e);
            return NaN;
        }
    } else {
        console.error("UngÃ¼ltige Eingabe fÃ¼r copy_model_and_evaluate.");
        return NaN;
    }

    // KRITISCHE PRÃœFUNG: Sicherstellen, dass die Datenstruktur gÃ¼ltig ist.
    if (!current_meta || current_meta.total === 0) {
        if (landscapeEvaluationErrorCount === 0) {
            console.error("KRITISCHER FEHLER (Internal): Gewichtstruktur konnte nicht abgeflacht/rekonstruiert werden (meta.total ist 0). Weitere Meldungen dieser Art werden unterdrÃ¼ckt.");
        }
        landscapeEvaluationErrorCount++;
        return NaN;
    }

    // Backend-Check (Debugging)
    if (!backendLogged) {
        console.log(`DEBUG: Aktives TF Backend: ${tf.getBackend()}`);
        backendLogged = true;
    }

    // ASYNCHRONER TEIL 1: MODELL KLONEN
    const cloned_model = await tf.models.modelFromJSON(model_config_json);

    // Kompilierungsdaten kopieren, um Isolation zu gewÃ¤hrleisten (NEU: Gesicherte Konfiguration verwenden)
    const compiled_data_copy = { ...plotter_compiled_config };

    // Modell SOFORT nach dem Klonen kompilieren.
    try {
        cloned_model.compile(compiled_data_copy);
    } catch (e) {
        console.error("Fehler beim Kompilieren des geklonten Modells:", e);
        cloned_model.dispose();
        return NaN;
    }

    let loss_value = [NaN];
    let tensors_to_dispose = null;
    let successful = false;

    // SYNCHRONER TEIL (GPU/CPU-Operationen) in tf.tidy
    tf.tidy(() => {
        let prediction = null;
        let loss_tensor = null;
        let X_temp_tensor = null;
        let Y_temp_tensor = null;
        try {
            // WICHTIG: Erzeuge die Tensoren aus den globalen Arrays nur fÃ¼r diesen Lauf.
            X_temp_tensor = tf.tensor(X_data_array, X_data_array.shape, 'float32');
            Y_temp_tensor = tf.tensor(Y_data_array, Y_data_array.shape, 'float32');


            // 1. Tensoren direkt aus Vektor und Meta-Daten erstellen
            const tensors = unflatten_to_tensors(current_vector, current_meta);
            tensors_to_dispose = tensors;

            // 2. Gewichte setzen
            cloned_model.setWeights(tensors);

            // Debug Logging der Shapes vor der fehleranfÃ¤lligen Operation
            if (landscapeEvaluationErrorCount === 0) {
                 console.log(`DEBUG: X_temp_tensor Shape vor Predict: ${X_temp_tensor.shape}`);
            }

            // 3. Verlust manuell berechnen (mit MSE)
            prediction = cloned_model.predict(X_temp_tensor);

            // Check der Prediction Shape, wenn sie erfolgreich war
            if (landscapeEvaluationErrorCount === 0) {
                 console.log(`DEBUG: Prediction Shape: ${prediction.shape}`);
            }

            loss_tensor = tf.losses.meanSquaredError(Y_temp_tensor, prediction);

            loss_value = loss_tensor.dataSync();
            successful = true;

        } catch (e) {
            // Dieser Catch-Block fÃ¤ngt den TypeError: 'backend' Fehler ab.
            if (landscapeEvaluationErrorCount === 0) {
                console.error("Fehler im synchronen tf.tidy-Block (SetWeights/Predict):", e);
                console.log(`DEBUG: Aktives TF Backend wÃ¤hrend des Fehlers: ${tf.getBackend()}`);
            }
            landscapeEvaluationErrorCount++;

            // Manuelles Disposing im Fehlerfall
            if (tensors_to_dispose) {
                 tensors_to_dispose.forEach(t => {
                     if (!t.isDisposed) t.dispose();
                 });
                 tensors_to_dispose = null;
            }
            loss_value = [NaN];
        } finally {
             // prediction und loss_tensor mÃ¼ssen manuell entsorgt werden.
             if (prediction && !prediction.isDisposed) prediction.dispose();
             if (loss_tensor && !loss_tensor.isDisposed) loss_tensor.dispose();
             // X_temp_tensor und Y_temp_tensor werden von tf.tidy entsorgt.
        }
    }); // Ende von tf.tidy()

    // MANUELLES DISPOSING
    if (cloned_model && !cloned_model.isDisposed) cloned_model.dispose();

    // Entsorge die Weight-Tensoren, falls nicht in tf.tidy entsorgt.
    if (tensors_to_dispose) tensors_to_dispose.forEach(t => {
        if (!t.isDisposed) t.dispose();
    });

    // ZÃ¤hler nur zurÃ¼cksetzen, wenn die Berechnung erfolgreich war
    if (successful && landscapeEvaluationErrorCount > 0) {
        landscapeEvaluationErrorCount = 0;
    }

    return loss_value[0];
}

// =================================================================
// â–¶ï¸ START PLOTTER (Hauptfunktion)
// =================================================================

async function start_landscape_plotter(d=3) {
    const container = document.getElementById('python_tab');
    if (container) {
        Plotly.purge(container);
        container.innerHTML = '';
    }

    // ZÃ¤hler zurÃ¼cksetzen, wenn der Plotter neu gestartet wird
    landscapeEvaluationErrorCount = 0;
    backendLogged = false;

    // --- 1. AUF DATEN UND MODELL WARTEN UND ARCHITEKTUR SPEICHERN ---
    console.log("Warte auf globale Daten und Modell und speichere Architektur...");
    try {
        await waitForData(() =>
            typeof array_sync === 'function' &&
            xy_data_global &&
            xy_data_global["x"] && xy_data_global["y"] &&
            xy_data_global["x"].shape && xy_data_global["y"].shape &&
            window.model &&
            typeof window.model.getWeights === 'function' &&
            window.global_model_data // Sicherstellen, dass die Kompilierungsdaten existieren
        );

        // SICHERER GEWICHTSABRUF MIT RETRY-LOGIK
        const weights_length = await get_safe_weights_length();

        if (weights_length === 0) {
             console.error("KRITISCHER FEHLER: Das globale Modell (window.model) enthÃ¤lt 0 Gewichte oder ist instabil.");
             return;
        }

        // ARCHITEKTUR SPEICHERN
        // HINWEIS: 'model' muss global oder als Alias von 'window.model' verfÃ¼gbar sein.
        const full_model_json_string = window.model.toJSON();

        try {
            model_config_json = JSON.parse(full_model_json_string);
        } catch (e) {
            model_config_json = full_model_json_string;
        }

        // Optional: Entferne das Gewichts-Manifest
        if (model_config_json && model_config_json.weightsManifest) {
             delete model_config_json.weightsManifest;
        }

        // NEU: KOMPILIERUNGSKONFIGURATION SPEICHERN
        plotter_compiled_config = { ...window.global_model_data };
        console.log("Kompilierungskonfiguration gesichert.");

        console.log("Modell-Architektur gespeichert fÃ¼r das Klonen.");
    } catch (error) {
        console.error("Plotter kann nicht gestartet werden:", error);
        return;
    }

    // --- 2. EVALUATIONSDATEN LADEN UND ALS ARRAY SPEICHERN ---
    X_data_array = null;
    Y_data_array = null;

    console.log("Lade und konvertiere Evaluierungsdaten in JS-Arrays...");

    // Lese die Tensoren einmal aus
    const X_tensor_to_dispose = xy_data_global["x"];
    const Y_tensor_to_dispose = xy_data_global["y"];

    // Speichere die Daten in den globalen Arrays
    X_data_array = array_sync(X_tensor_to_dispose);
    Y_data_array = array_sync(Y_tensor_to_dispose);

    // Speichere die Shapes in den Arrays fÃ¼r die spÃ¤tere Tensorerzeugung
    X_data_array.shape = X_tensor_to_dispose.shape;
    Y_data_array.shape = Y_tensor_to_dispose.shape;

    // WICHTIG: Die ursprÃ¼nglichen globalen Tensoren MÃœSSEN freigegeben werden.
    X_tensor_to_dispose.dispose();
    Y_tensor_to_dispose.dispose();

    // Alte globale Referenzen nullen (nur fÃ¼r Konsistenz)
    X_eval = null;
    Y_eval = null;


    console.log(`X_data_array Shape: ${X_data_array.shape}, Y_data_array Shape: ${Y_data_array.shape}`);

    // --- 3. PLOTTER INITIALISIEREN ---
    var plotter = make_loss_landscape_plotter({
      container_id:'python_tab',
      get_weights_fn: async ()=> await get_weights_as_json(),
      current_loss_fn: async ()=> current_loss_value,

      // EVAL_FN ruft copy_model_and_evaluate auf
      eval_fn: async (arg1, arg2) => {
             try {
                 return await copy_model_and_evaluate(arg1, arg2);
             } catch(e) {
                 // UNERWARTETER FEHLER: Drosselung
                 if (landscapeEvaluationErrorCount === 0) {
                      console.error("UNERWARTETER FEHLER im asynchronen Evaluierungsfluss:", e);
                      console.warn("Weitere Fehler wÃ¤hrend der Gitterauswertung werden unterdrÃ¼ckt, bis der Plotter neu gestartet wird.");
                 }
                 landscapeEvaluationErrorCount++;
                 return NaN;
             }
      },
      projection:'pca',
      dims:d,
      auto_poll_ms:1000,
      grid:{ enabled:true, steps:15 }
    });

    // AufrÃ¤umfunktion fÃ¼r die globalen Arrays
    plotter.dispose_eval_data = () => {
        X_data_array = null;
        Y_data_array = null;
        model_config_json = null;
        plotter_compiled_config = null; // NEU: Kompilierungskonfiguration freigeben
        console.log("Evaluierungsdaten (Arrays) und Modellkonfiguration freigegeben.");
    };

    await plotter.init_from_get_weights();
    plotter.start_auto_poll();

    return plotter;
}
